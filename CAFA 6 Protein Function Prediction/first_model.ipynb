{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b1a78a",
   "metadata": {},
   "source": [
    "# CAFA 6 Protein Function Prediction\n",
    "\n",
    "This notebook builds a deep learning model to predict protein function based on amino acid sequences using GPU acceleration.\n",
    "\n",
    "## Overview\n",
    "- **Task**: Predict Gene Ontology (GO) terms for proteins based on amino acid sequences\n",
    "- **Evaluation**: Weighted F1-measure across three subontologies (MF, BP, CC)\n",
    "- **Data**: Protein sequences in FASTA format with associated GO terms\n",
    "- **Approach**: Deep learning with transformer-based protein language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e89682c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing GPU availability and performance...\n",
      "PyTorch version: 2.7.1+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "Number of GPUs: 1\n",
      "GPU 0: NVIDIA RTX 5000 Ada Generation Laptop GPU\n",
      "  Memory: 17.2 GB\n",
      "  Compute capability: 8.9\n",
      "\n",
      "‚ö° Testing GPU performance...\n",
      "‚úÖ GPU matrix multiplication (5000x5000): 0.031 seconds\n",
      "üñ•Ô∏è  CPU matrix multiplication (5000x5000): 0.272 seconds\n",
      "üöÄ GPU speedup: 8.8x faster\n",
      "\n",
      "üíæ GPU Memory:\n",
      "  Allocated: 0.31 GB\n",
      "  Reserved: 0.32 GB\n",
      "üñ•Ô∏è  CPU matrix multiplication (5000x5000): 0.272 seconds\n",
      "üöÄ GPU speedup: 8.8x faster\n",
      "\n",
      "üíæ GPU Memory:\n",
      "  Allocated: 0.31 GB\n",
      "  Reserved: 0.32 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Test GPU availability and performance\n",
    "print(\"üîç Testing GPU availability and performance...\")\n",
    "\n",
    "\n",
    "# Basic CUDA detection\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        gpu_props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"GPU {i}: {gpu_props.name}\")\n",
    "        print(f\"  Memory: {gpu_props.total_memory / 1e9:.1f} GB\")\n",
    "        print(f\"  Compute capability: {gpu_props.major}.{gpu_props.minor}\")\n",
    "    \n",
    "    # Test GPU performance\n",
    "    print(\"\\n‚ö° Testing GPU performance...\")\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    # Create test tensors\n",
    "    size = 5000\n",
    "    a = torch.randn(size, size, device=device)\n",
    "    b = torch.randn(size, size, device=device)\n",
    "    \n",
    "    # Time matrix multiplication\n",
    "    start_time = time.time()\n",
    "    c = torch.mm(a, b)\n",
    "    torch.cuda.synchronize()  # Wait for GPU operation to complete\n",
    "    gpu_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"‚úÖ GPU matrix multiplication ({size}x{size}): {gpu_time:.3f} seconds\")\n",
    "    \n",
    "    # Compare with CPU\n",
    "    a_cpu = a.cpu()\n",
    "    b_cpu = b.cpu()\n",
    "    start_time = time.time()\n",
    "    c_cpu = torch.mm(a_cpu, b_cpu)\n",
    "    cpu_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"üñ•Ô∏è  CPU matrix multiplication ({size}x{size}): {cpu_time:.3f} seconds\")\n",
    "    print(f\"üöÄ GPU speedup: {cpu_time/gpu_time:.1f}x faster\")\n",
    "    \n",
    "    # Memory info\n",
    "    print(f\"\\nüíæ GPU Memory:\")\n",
    "    print(f\"  Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "    print(f\"  Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå CUDA not available\")\n",
    "    print(\"Possible solutions:\")\n",
    "    print(\"1. Install PyTorch with CUDA support:\")\n",
    "    print(\"   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
    "    print(\"2. Check NVIDIA driver installation\")\n",
    "    print(\"3. Verify GPU is recognized by system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28e19338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "GPU not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from Bio import SeqIO\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "else:\n",
    "    print(\"GPU not available. Using CPU.\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d0b4df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File paths defined:\n",
      "  train_sequences.fasta: EXISTS\n",
      "  train_terms.tsv: EXISTS\n",
      "  IA.tsv: EXISTS\n",
      "\n",
      "Loading IA weights...\n",
      "Loaded 40122 GO terms with weights\n",
      "      GO_term    weight\n",
      "0  GO:0000001  0.000000\n",
      "1  GO:0000002  2.849666\n",
      "2  GO:0000011  0.137504\n",
      "3  GO:0000012  6.038630\n",
      "4  GO:0000017  0.514573\n"
     ]
    }
   ],
   "source": [
    "# Define file paths\n",
    "base_path = r\"c:\\Users\\USANBRO30\\OneDrive - ABB\\Documents\\GitHub\\Monthly-Flash-Report-Pricing\\kaggle_comps\\CAFA 6 Protein Function Prediction\"\n",
    "train_sequences_path = os.path.join(base_path, \"Train\", \"train_sequences.fasta\")\n",
    "train_terms_path = os.path.join(base_path, \"Train\", \"train_terms.tsv\")\n",
    "ia_weights_path = os.path.join(base_path, \"IA.tsv\")\n",
    "sample_submission_path = os.path.join(base_path, \"sample_submission.tsv\")\n",
    "test_sequences_path = os.path.join(base_path, \"Test\", \"testsuperset.fasta\")\n",
    "\n",
    "print(\"File paths defined:\")\n",
    "for path in [train_sequences_path, train_terms_path, ia_weights_path]:\n",
    "    print(f\"  {os.path.basename(path)}: {'EXISTS' if os.path.exists(path) else 'NOT FOUND'}\")\n",
    "    \n",
    "# Load Information Accretion (IA) weights for GO terms\n",
    "print(\"\\nLoading IA weights...\")\n",
    "ia_weights = pd.read_csv(ia_weights_path, sep='\\t', header=None, names=['GO_term', 'weight'])\n",
    "print(f\"Loaded {len(ia_weights)} GO terms with weights\")\n",
    "print(ia_weights.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1a5231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training terms...\n",
      "Loaded 537027 annotations\n",
      "Unique proteins: 82404\n",
      "Unique GO terms: 26125\n",
      "\n",
      "Aspect distribution:\n",
      "aspect\n",
      "P    250805\n",
      "C    157770\n",
      "F    128452\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data:\n",
      "  EntryID        term aspect\n",
      "0  Q5W0B1  GO:0000785      C\n",
      "1  Q5W0B1  GO:0004842      F\n",
      "2  Q5W0B1  GO:0051865      P\n",
      "3  Q5W0B1  GO:0006275      P\n",
      "4  Q5W0B1  GO:0006513      P\n"
     ]
    }
   ],
   "source": [
    "# Load training terms data\n",
    "print(\"Loading training terms...\")\n",
    "train_terms = pd.read_csv(train_terms_path, sep='\\t')\n",
    "print(f\"Loaded {len(train_terms)} annotations\")\n",
    "print(f\"Unique proteins: {train_terms['EntryID'].nunique()}\")\n",
    "print(f\"Unique GO terms: {train_terms['term'].nunique()}\")\n",
    "print(\"\\nAspect distribution:\")\n",
    "print(train_terms['aspect'].value_counts())\n",
    "print(\"\\nSample data:\")\n",
    "print(train_terms.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d8166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading protein sequences...\n",
      "Loaded 1000 sequences...\n",
      "Loaded 2000 sequences...\n",
      "Loaded 3000 sequences...\n",
      "Loaded 4000 sequences...\n",
      "Loaded 5000 sequences...\n",
      "Loaded 6000 sequences...\n",
      "Loaded 7000 sequences...\n",
      "Loaded 8000 sequences...\n",
      "Loaded 9000 sequences...\n",
      "Loaded 10000 sequences...\n",
      "Loaded 11000 sequences...\n",
      "Loaded 12000 sequences...\n",
      "Loaded 13000 sequences...\n",
      "Loaded 14000 sequences...\n",
      "Loaded 15000 sequences...\n",
      "Loaded 16000 sequences...\n",
      "Loaded 17000 sequences...\n",
      "Loaded 18000 sequences...\n",
      "Loaded 19000 sequences...\n",
      "Loaded 20000 sequences...\n",
      "Loaded 21000 sequences...\n",
      "Loaded 22000 sequences...\n",
      "Loaded 23000 sequences...\n",
      "Loaded 24000 sequences...\n",
      "Loaded 25000 sequences...\n",
      "Loaded 26000 sequences...\n",
      "Loaded 27000 sequences...\n",
      "Loaded 28000 sequences...\n",
      "Loaded 29000 sequences...\n",
      "Loaded 30000 sequences...\n",
      "Loaded 31000 sequences...\n",
      "Loaded 32000 sequences...\n",
      "Loaded 33000 sequences...\n",
      "Loaded 34000 sequences...\n",
      "Loaded 35000 sequences...\n",
      "Loaded 36000 sequences...\n",
      "Loaded 37000 sequences...\n",
      "Loaded 38000 sequences...\n",
      "Loaded 39000 sequences...\n",
      "Loaded 40000 sequences...\n",
      "Loaded 41000 sequences...\n",
      "Loaded 42000 sequences...\n",
      "Loaded 43000 sequences...\n",
      "Loaded 44000 sequences...\n",
      "Loaded 45000 sequences...\n",
      "Loaded 46000 sequences...\n",
      "Loaded 47000 sequences...\n",
      "Loaded 48000 sequences...\n",
      "Loaded 49000 sequences...\n",
      "Loaded 50000 sequences...\n",
      "Loaded 51000 sequences...\n",
      "Loaded 52000 sequences...\n",
      "Loaded 53000 sequences...\n",
      "Loaded 54000 sequences...\n",
      "Loaded 55000 sequences...\n",
      "Loaded 56000 sequences...\n",
      "Loaded 57000 sequences...\n",
      "Loaded 58000 sequences...\n",
      "Loaded 59000 sequences...\n",
      "Loaded 60000 sequences...\n",
      "Loaded 61000 sequences...\n",
      "Loaded 62000 sequences...\n",
      "Loaded 63000 sequences...\n",
      "Loaded 64000 sequences...\n",
      "Loaded 65000 sequences...\n",
      "Loaded 66000 sequences...\n",
      "Loaded 67000 sequences...\n",
      "Loaded 68000 sequences...\n",
      "Loaded 69000 sequences...\n",
      "Loaded 70000 sequences...\n",
      "Loaded 71000 sequences...\n",
      "Loaded 72000 sequences...\n",
      "Loaded 73000 sequences...\n",
      "Loaded 74000 sequences...\n",
      "Loaded 75000 sequences...\n",
      "Loaded 76000 sequences...\n",
      "Loaded 77000 sequences...\n",
      "Loaded 78000 sequences...\n",
      "Loaded 79000 sequences...\n",
      "Loaded 80000 sequences...\n",
      "Loaded 81000 sequences...\n",
      "Loaded 82000 sequences...\n",
      "Total sequences loaded: 82404\n",
      "\n",
      "Sequence statistics:\n",
      "  Min length: 3\n",
      "  Max length: 35213\n",
      "  Mean length: 525.8\n",
      "  Median length: 409.0\n",
      "\n",
      "Sample sequence (sp|A0A0C5B5G6|MOTSC_HUMAN):\n",
      "Length: 16\n",
      "First 100 amino acids: MRWQEMGYIFYPRKLR\n"
     ]
    }
   ],
   "source": [
    "# Function to load sequences from FASTA file efficiently\n",
    "def load_sequences_batch(fasta_path, batch_size=1000):\n",
    "    \"\"\"Load protein sequences in batches to handle large files efficiently\"\"\"\n",
    "    sequences = {}\n",
    "    count = 0\n",
    "    \n",
    "    with open(fasta_path, 'r') as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            sequences[record.id] = str(record.seq)\n",
    "            count += 1\n",
    "            if count % batch_size == 0:\n",
    "                print(f\"Loaded {count} sequences...\")\n",
    "                \n",
    "    print(f\"Total sequences loaded: {count}\")\n",
    "    return sequences\n",
    "\n",
    "# Load training sequences (this might take a while due to file size)\n",
    "print(\"Loading protein sequences...\")\n",
    "train_sequences = load_sequences_batch(train_sequences_path)\n",
    "\n",
    "# Get statistics about sequence lengths\n",
    "sequence_lengths = [len(seq) for seq in train_sequences.values()]\n",
    "print(f\"\\nSequence statistics:\")\n",
    "print(f\"  Min length: {min(sequence_lengths)}\")\n",
    "print(f\"  Max length: {max(sequence_lengths)}\")\n",
    "print(f\"  Mean length: {np.mean(sequence_lengths):.1f}\")\n",
    "print(f\"  Median length: {np.median(sequence_lengths):.1f}\")\n",
    "\n",
    "# Show a sample sequence\n",
    "sample_id = list(train_sequences.keys())[0]\n",
    "print(f\"\\nSample sequence ({sample_id}):\")\n",
    "print(f\"Length: {len(train_sequences[sample_id])}\")\n",
    "print(f\"First 100 amino acids: {train_sequences[sample_id][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4386e710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training data...\n",
      "Proteins with both sequences and terms: 0\n",
      "Total GO terms: 26125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing protein labels: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared labels for 0 proteins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create dataset class for protein sequences\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, sequences, labels, max_length=1024):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Create amino acid vocabulary (20 standard amino acids + padding + unknown)\n",
    "        self.aa_vocab = {\n",
    "            'A': 1, 'R': 2, 'N': 3, 'D': 4, 'C': 5, 'Q': 6, 'E': 7, 'G': 8,\n",
    "            'H': 9, 'I': 10, 'L': 11, 'K': 12, 'M': 13, 'F': 14, 'P': 15, 'S': 16,\n",
    "            'T': 17, 'W': 18, 'Y': 19, 'V': 20, '<PAD>': 0, '<UNK>': 21\n",
    "        }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        labels = self.labels[idx]\n",
    "        \n",
    "        # Convert sequence to indices\n",
    "        seq_indices = [self.aa_vocab.get(aa, self.aa_vocab['<UNK>']) for aa in sequence]\n",
    "        \n",
    "        # Truncate or pad sequence\n",
    "        if len(seq_indices) > self.max_length:\n",
    "            seq_indices = seq_indices[:self.max_length]\n",
    "        else:\n",
    "            seq_indices += [self.aa_vocab['<PAD>']] * (self.max_length - len(seq_indices))\n",
    "        \n",
    "        return torch.tensor(seq_indices, dtype=torch.long), torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# Prepare data for training\n",
    "print(\"Preparing training data...\")\n",
    "\n",
    "# Filter proteins that exist in both sequences and terms\n",
    "protein_ids = set(train_sequences.keys()) & set(train_terms['EntryID'].unique())\n",
    "print(f\"Proteins with both sequences and terms: {len(protein_ids)}\")\n",
    "\n",
    "# Create labels for each protein\n",
    "protein_labels = {}\n",
    "all_go_terms = sorted(train_terms['term'].unique())\n",
    "go_term_to_idx = {term: idx for idx, term in enumerate(all_go_terms)}\n",
    "\n",
    "print(f\"Total GO terms: {len(all_go_terms)}\")\n",
    "\n",
    "# Create binary labels for each protein\n",
    "for protein_id in tqdm(protein_ids, desc=\"Processing protein labels\"):\n",
    "    protein_go_terms = train_terms[train_terms['EntryID'] == protein_id]['term'].values\n",
    "    label_vector = np.zeros(len(all_go_terms), dtype=np.float32)\n",
    "    \n",
    "    for go_term in protein_go_terms:\n",
    "        if go_term in go_term_to_idx:\n",
    "            label_vector[go_term_to_idx[go_term]] = 1.0\n",
    "    \n",
    "    protein_labels[protein_id] = label_vector\n",
    "\n",
    "print(f\"Prepared labels for {len(protein_labels)} proteins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9bf3b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sequence IDs:\n",
      "  sp|A0A0C5B5G6|MOTSC_HUMAN\n",
      "  sp|A0JNW5|BLT3B_HUMAN\n",
      "  sp|A0JP26|POTB3_HUMAN\n",
      "  sp|A0PK11|CLRN2_HUMAN\n",
      "  sp|A1A4S6|RHG10_HUMAN\n",
      "\n",
      "Sample term IDs:\n",
      "  Q5W0B1\n",
      "  Q3EC77\n",
      "  Q8IZR5\n",
      "  Q8R2Z3\n",
      "  P63027\n",
      "\n",
      "Trying to extract protein IDs...\n",
      "  sp|A0A0C5B5G6|MOTSC_HUMAN -> A0A0C5B5G6\n",
      "  sp|A0JNW5|BLT3B_HUMAN -> A0JNW5\n",
      "  sp|A0JP26|POTB3_HUMAN -> A0JP26\n",
      "  sp|A0PK11|CLRN2_HUMAN -> A0PK11\n",
      "  sp|A1A4S6|RHG10_HUMAN -> A1A4S6\n",
      "\n",
      "Checking matches...\n",
      "Found 5 matching protein IDs\n"
     ]
    }
   ],
   "source": [
    "# Investigate the ID format differences\n",
    "print(\"Sample sequence IDs:\")\n",
    "seq_ids = list(train_sequences.keys())[:5]\n",
    "for seq_id in seq_ids:\n",
    "    print(f\"  {seq_id}\")\n",
    "\n",
    "print(\"\\nSample term IDs:\")\n",
    "term_ids = train_terms['EntryID'].unique()[:5]\n",
    "for term_id in term_ids:\n",
    "    print(f\"  {term_id}\")\n",
    "    \n",
    "# Check if we can extract protein IDs from sequence headers\n",
    "print(\"\\nTrying to extract protein IDs...\")\n",
    "extracted_ids = []\n",
    "for seq_id in seq_ids:\n",
    "    # Try to extract the actual protein ID from FASTA header\n",
    "    if '|' in seq_id:\n",
    "        # Format like \"sp|A0A0C5B5G6|MOTSC_HUMAN\" -> extract \"A0A0C5B5G6\"\n",
    "        parts = seq_id.split('|')\n",
    "        if len(parts) >= 2:\n",
    "            extracted_id = parts[1]\n",
    "            extracted_ids.append(extracted_id)\n",
    "            print(f\"  {seq_id} -> {extracted_id}\")\n",
    "\n",
    "# Check if extracted IDs match term IDs\n",
    "print(f\"\\nChecking matches...\")\n",
    "matches = set(extracted_ids) & set(train_terms['EntryID'].unique())\n",
    "print(f\"Found {len(matches)} matching protein IDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df1596b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå CUDA not available. Using CPU.\n",
      "üìä GPU Status from nvidia-smi:\n",
      "Wed Oct 15 21:21:58 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 573.57                 Driver Version: 573.57         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|       ...\n",
      "\n",
      "üéØ Final device configuration: cpu\n"
     ]
    }
   ],
   "source": [
    "# Enhanced GPU detection and configuration for NVIDIA A5000\n",
    "import subprocess\n",
    "\n",
    "def check_gpu_status():\n",
    "    \"\"\"Check GPU availability and configure torch for optimal performance\"\"\"\n",
    "    \n",
    "    # Check CUDA availability\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"‚úÖ CUDA is available!\")\n",
    "        \n",
    "        # Get GPU information\n",
    "        gpu_count = torch.cuda.device_count()\n",
    "        current_device = torch.cuda.current_device()\n",
    "        gpu_name = torch.cuda.get_device_name(current_device)\n",
    "        \n",
    "        print(f\"üîß GPU Count: {gpu_count}\")\n",
    "        print(f\"üéØ Current Device: {current_device}\")\n",
    "        print(f\"üöÄ GPU Name: {gpu_name}\")\n",
    "        print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(current_device).total_memory / 1e9:.1f} GB\")\n",
    "        \n",
    "        # Check if it's an A5000\n",
    "        if \"A5000\" in gpu_name or \"RTX A5000\" in gpu_name:\n",
    "            print(\"üéâ NVIDIA A5000 detected! This is perfect for deep learning.\")\n",
    "            \n",
    "        # Set GPU optimizations\n",
    "        torch.backends.cudnn.benchmark = True  # Optimize for consistent input sizes\n",
    "        torch.backends.cudnn.deterministic = False  # Allow non-deterministic for better performance\n",
    "        \n",
    "        # Clear GPU cache\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        print(\"‚ùå CUDA not available. Using CPU.\")\n",
    "        try:\n",
    "            # Try to get more information about why CUDA isn't available\n",
    "            result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)\n",
    "            if result.returncode == 0:\n",
    "                print(\"üìä GPU Status from nvidia-smi:\")\n",
    "                print(result.stdout[:500] + \"...\" if len(result.stdout) > 500 else result.stdout)\n",
    "            else:\n",
    "                print(\"üîç nvidia-smi not available or failed\")\n",
    "        except:\n",
    "            print(\"üîç Could not run nvidia-smi\")\n",
    "            \n",
    "        return torch.device('cpu')\n",
    "\n",
    "# Update device with enhanced detection\n",
    "device = check_gpu_status()\n",
    "\n",
    "# Set memory management for GPU\n",
    "if device.type == 'cuda':\n",
    "    # Enable memory fraction to prevent OOM\n",
    "    torch.cuda.set_per_process_memory_fraction(0.8)  # Use 80% of GPU memory\n",
    "    print(f\"üîß GPU memory management configured\")\n",
    "    print(f\"üìä Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9 * 0.8:.1f} GB (80% of total)\")\n",
    "\n",
    "print(f\"\\nüéØ Final device configuration: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a985954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.7.1+cu118\n",
      "Uninstalling torch-2.7.1+cu118:\n",
      "  Successfully uninstalled torch-2.7.1+cu118\n",
      "Found existing installation: torchvision 0.22.1+cu118\n",
      "Uninstalling torchvision-0.22.1+cu118:\n",
      "  Successfully uninstalled torchvision-0.22.1+cu118\n",
      "Found existing installation: torchaudio 2.7.1+cu118\n",
      "Uninstalling torchaudio-2.7.1+cu118:\n",
      "  Successfully uninstalled torchaudio-2.7.1+cu118\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "üîÑ PyTorch reinstalled with CUDA 12.1 support\n",
      "‚ö†Ô∏è  Please restart the kernel after installation for changes to take effect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
      "ERROR: No matching distribution found for torch\n"
     ]
    }
   ],
   "source": [
    "# Install PyTorch with proper CUDA support for A5000\n",
    "%pip uninstall torch torchvision torchaudio -y\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "print(\"üîÑ PyTorch reinstalled with CUDA 12.1 support\")\n",
    "print(\"‚ö†Ô∏è  Please restart the kernel after installation for changes to take effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c30517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp313-cp313-win_amd64.whl.metadata (27 kB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp313-cp313-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\usanbro30\\appdata\\local\\anaconda3\\envs\\datascience\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\usanbro30\\appdata\\local\\anaconda3\\envs\\datascience\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\usanbro30\\appdata\\local\\anaconda3\\envs\\datascience\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\usanbro30\\appdata\\local\\anaconda3\\envs\\datascience\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usanbro30\\appdata\\local\\anaconda3\\envs\\datascience\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\usanbro30\\appdata\\local\\anaconda3\\envs\\datascience\\lib\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usanbro30\\appdata\\local\\anaconda3\\envs\\datascience\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\usanbro30\\appdata\\local\\anaconda3\\envs\\datascience\\lib\\site-packages (from torchvision) (2.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\usanbro30\\appdata\\local\\anaconda3\\envs\\datascience\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\usanbro30\\appdata\\local\\anaconda3\\envs\\datascience\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usanbro30\\appdata\\local\\anaconda3\\envs\\datascience\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp313-cp313-win_amd64.whl (2817.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp313-cp313-win_amd64.whl (5.5 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp313-cp313-win_amd64.whl (4.1 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ---------------------------------------- 0/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   ------------- -------------------------- 1/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   -------------------------- ------------- 2/3 [torchaudio]\n",
      "   ---------------------------------------- 3/3 [torchaudio]\n",
      "\n",
      "Successfully installed torch-2.7.1+cu118 torchaudio-2.7.1+cu118 torchvision-0.22.1+cu118\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "üîÑ Attempting PyTorch installation with CUDA 11.8...\n",
      "This should be compatible with your NVIDIA A5000\n"
     ]
    }
   ],
   "source": [
    "# Try installing PyTorch with CUDA 11.8 (more stable)\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "print(\"üîÑ Attempting PyTorch installation with CUDA 11.8...\")\n",
    "print(\"This should be compatible with your NVIDIA A5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aee113e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Testing GPU detection after PyTorch reinstall...\n",
      "‚ùå CUDA still not available\n",
      "\n",
      "üéØ Final device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Restart torch imports and test GPU detection\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "print(\"üîÑ Testing GPU detection after PyTorch reinstall...\")\n",
    "\n",
    "# Test CUDA availability\n",
    "if torch.cuda.is_available():\n",
    "    print(\"‚úÖ CUDA is now available!\")\n",
    "    \n",
    "    # Get GPU information\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    current_device = torch.cuda.current_device()\n",
    "    gpu_name = torch.cuda.get_device_name(current_device)\n",
    "    gpu_properties = torch.cuda.get_device_properties(current_device)\n",
    "    \n",
    "    print(f\"üîß GPU Count: {gpu_count}\")\n",
    "    print(f\"üéØ Current Device: {current_device}\")\n",
    "    print(f\"üöÄ GPU Name: {gpu_name}\")\n",
    "    print(f\"üíæ Total GPU Memory: {gpu_properties.total_memory / 1e9:.1f} GB\")\n",
    "    print(f\"üèóÔ∏è  Multi-Processor Count: {gpu_properties.multi_processor_count}\")\n",
    "    print(f\"‚ö° CUDA Capability: {gpu_properties.major}.{gpu_properties.minor}\")\n",
    "    \n",
    "    # Test basic GPU operation\n",
    "    test_tensor = torch.rand(1000, 1000).cuda()\n",
    "    result = torch.mm(test_tensor, test_tensor)\n",
    "    print(f\"‚úÖ GPU test successful! Result shape: {result.shape}\")\n",
    "    \n",
    "    # Configure optimizations for A5000\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    device = torch.device('cuda')\n",
    "    print(\"üéâ NVIDIA A5000 is ready for deep learning!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå CUDA still not available\")\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(f\"\\nüéØ Final device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2526dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Debugging CUDA detection...\n",
      "PyTorch version: 2.6.0\n",
      "PyTorch CUDA compiled version: None\n",
      "PyTorch cuDNN version: None\n",
      "CUDA runtime version: None\n",
      "Is CUDA available: False\n",
      "CUDA not available. Possible reasons:\n",
      "1. PyTorch was built without CUDA support\n",
      "2. CUDA runtime version mismatch\n",
      "3. GPU driver issues\n",
      "\n",
      "üìù Continuing with CPU for now. The model will still work!\n",
      "üí° We'll build a GPU-ready model that can be easily transferred to GPU later.\n",
      "Current device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Debug CUDA detection issues\n",
    "print(\"üîç Debugging CUDA detection...\")\n",
    "\n",
    "# Check PyTorch version and build info\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch CUDA compiled version: {torch.version.cuda}\")\n",
    "print(f\"PyTorch cuDNN version: {torch.backends.cudnn.version()}\")\n",
    "\n",
    "# Check if CUDA runtime is available\n",
    "try:\n",
    "    print(f\"CUDA runtime version: {torch.version.cuda}\")\n",
    "    print(f\"Is CUDA available: {torch.cuda.is_available()}\")\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"CUDA not available. Possible reasons:\")\n",
    "        print(\"1. PyTorch was built without CUDA support\")\n",
    "        print(\"2. CUDA runtime version mismatch\")\n",
    "        print(\"3. GPU driver issues\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error checking CUDA: {e}\")\n",
    "\n",
    "# Let's continue with the model development using CPU for now\n",
    "# We can optimize it later once GPU is working\n",
    "print(\"\\nüìù Continuing with CPU for now. The model will still work!\")\n",
    "print(\"üí° We'll build a GPU-ready model that can be easily transferred to GPU later.\")\n",
    "\n",
    "device = torch.device('cpu')  # Will update this once GPU is working\n",
    "print(f\"Current device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82b4f60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Fixing protein ID matching...\n",
      "Created mapping for 82404 protein IDs\n",
      "Proteins available in both sequences and terms: 82404\n",
      "üìä Preparing training data...\n",
      "Total GO terms to predict: 26125\n",
      "Using subset of 5000 proteins for initial training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing proteins: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [01:28<00:00, 56.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training set: 5000 proteins\n",
      "Average GO terms per protein: 6.59\n",
      "Label matrix shape: (5000, 26125)\n",
      "Label sparsity: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# Fix protein ID matching and prepare training data\n",
    "print(\"üîß Fixing protein ID matching...\")\n",
    "\n",
    "# Create a mapping from FASTA headers to protein IDs\n",
    "sequence_id_mapping = {}\n",
    "for seq_id in train_sequences.keys():\n",
    "    if '|' in seq_id:\n",
    "        # Extract protein ID from FASTA header (e.g., \"sp|A0A0C5B5G6|MOTSC_HUMAN\" -> \"A0A0C5B5G6\")\n",
    "        parts = seq_id.split('|')\n",
    "        if len(parts) >= 2:\n",
    "            protein_id = parts[1]\n",
    "            sequence_id_mapping[protein_id] = seq_id\n",
    "\n",
    "print(f\"Created mapping for {len(sequence_id_mapping)} protein IDs\")\n",
    "\n",
    "# Find proteins that exist in both sequences and terms using the mapping\n",
    "available_protein_ids = set(sequence_id_mapping.keys()) & set(train_terms['EntryID'].unique())\n",
    "print(f\"Proteins available in both sequences and terms: {len(available_protein_ids)}\")\n",
    "\n",
    "# Prepare training data\n",
    "print(\"üìä Preparing training data...\")\n",
    "\n",
    "# Get all unique GO terms and create label mapping\n",
    "all_go_terms = sorted(train_terms['term'].unique())\n",
    "go_term_to_idx = {term: idx for idx, term in enumerate(all_go_terms)}\n",
    "print(f\"Total GO terms to predict: {len(all_go_terms)}\")\n",
    "\n",
    "# Create training sequences and labels\n",
    "train_sequences_list = []\n",
    "train_labels_list = []\n",
    "train_protein_ids = []\n",
    "\n",
    "# Limit to a subset for initial development (to speed up training)\n",
    "protein_subset = list(available_protein_ids)[:5000]  # Start with 5000 proteins\n",
    "print(f\"Using subset of {len(protein_subset)} proteins for initial training\")\n",
    "\n",
    "for protein_id in tqdm(protein_subset, desc=\"Processing proteins\"):\n",
    "    # Get sequence\n",
    "    fasta_id = sequence_id_mapping[protein_id]\n",
    "    sequence = train_sequences[fasta_id]\n",
    "    \n",
    "    # Get GO terms for this protein\n",
    "    protein_go_terms = train_terms[train_terms['EntryID'] == protein_id]['term'].values\n",
    "    \n",
    "    # Create binary label vector\n",
    "    label_vector = np.zeros(len(all_go_terms), dtype=np.float32)\n",
    "    for go_term in protein_go_terms:\n",
    "        if go_term in go_term_to_idx:\n",
    "            label_vector[go_term_to_idx[go_term]] = 1.0\n",
    "    \n",
    "    # Only include proteins with at least one GO term\n",
    "    if label_vector.sum() > 0:\n",
    "        train_sequences_list.append(sequence)\n",
    "        train_labels_list.append(label_vector)\n",
    "        train_protein_ids.append(protein_id)\n",
    "\n",
    "print(f\"Final training set: {len(train_sequences_list)} proteins\")\n",
    "print(f\"Average GO terms per protein: {np.mean([labels.sum() for labels in train_labels_list]):.2f}\")\n",
    "\n",
    "# Convert to numpy arrays\n",
    "train_labels_array = np.array(train_labels_list)\n",
    "print(f\"Label matrix shape: {train_labels_array.shape}\")\n",
    "print(f\"Label sparsity: {(train_labels_array.sum() / train_labels_array.size):.4f}\")  # Fraction of positive labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18332869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è  Initializing Protein Function Prediction Model...\n",
      "üìä Model Statistics:\n",
      "   Total parameters: 7,574,541\n",
      "   Trainable parameters: 7,574,541\n",
      "   Model size: ~30.3 MB (float32)\n",
      "\n",
      "üéØ Model ready for training on cpu!\n"
     ]
    }
   ],
   "source": [
    "# Define the protein function prediction neural network\n",
    "class ProteinFunctionPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size=22, embedding_dim=128, hidden_dim=512, num_classes=26125, max_length=1024, dropout=0.3):\n",
    "        super(ProteinFunctionPredictor, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Embedding layer for amino acids\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # Convolutional layers for local pattern detection\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=7, padding=3)\n",
    "        \n",
    "        # Bidirectional LSTM for sequence modeling\n",
    "        self.lstm = nn.LSTM(hidden_dim * 3, hidden_dim, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        # Attention mechanism for important region focus\n",
    "        self.attention = nn.MultiheadAttention(hidden_dim * 2, num_heads=8, dropout=dropout, batch_first=True)\n",
    "        \n",
    "        # Classification layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.classifier = nn.Linear(hidden_dim // 2, num_classes)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize model weights\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "            elif isinstance(module, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(module.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        \n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_len, embedding_dim)\n",
    "        embedded = embedded.transpose(1, 2)  # (batch_size, embedding_dim, seq_len)\n",
    "        \n",
    "        # Convolutional layers for different kernel sizes\n",
    "        conv_out1 = self.relu(self.conv1(embedded))\n",
    "        conv_out2 = self.relu(self.conv2(embedded))\n",
    "        conv_out3 = self.relu(self.conv3(embedded))\n",
    "        \n",
    "        # Concatenate conv outputs\n",
    "        conv_concat = torch.cat([conv_out1, conv_out2, conv_out3], dim=1)  # (batch_size, hidden_dim*3, seq_len)\n",
    "        conv_concat = conv_concat.transpose(1, 2)  # (batch_size, seq_len, hidden_dim*3)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, (hidden, cell) = self.lstm(conv_concat)  # (batch_size, seq_len, hidden_dim*2)\n",
    "        \n",
    "        # Self-attention\n",
    "        attended_out, attention_weights = self.attention(lstm_out, lstm_out, lstm_out)\n",
    "        \n",
    "        # Global max pooling\n",
    "        pooled = torch.max(attended_out, dim=1)[0]  # (batch_size, hidden_dim*2)\n",
    "        \n",
    "        # Classification layers\n",
    "        x = self.dropout(pooled)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        output = self.sigmoid(self.classifier(x))  # Multi-label classification\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Initialize the model\n",
    "print(\"üèóÔ∏è  Initializing Protein Function Prediction Model...\")\n",
    "model = ProteinFunctionPredictor(\n",
    "    vocab_size=22,  # 20 amino acids + padding + unknown\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=256,  # Reduced for CPU training\n",
    "    num_classes=len(all_go_terms),\n",
    "    max_length=512,  # Reduced max length for memory efficiency\n",
    "    dropout=0.3\n",
    ")\n",
    "\n",
    "# Move model to device (CPU for now, GPU-ready)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"üìä Model Statistics:\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"   Model size: ~{total_params * 4 / 1e6:.1f} MB (float32)\")\n",
    "\n",
    "print(f\"\\nüéØ Model ready for training on {device}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9d1796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Creating training dataset...\n",
      "Training set: 4000 proteins\n",
      "Validation set: 1000 proteins\n",
      "üìä Data loaders created:\n",
      "   Training batches: 500\n",
      "   Validation batches: 125\n",
      "   Batch size: 8\n",
      "\n",
      "üß™ Testing data loader...\n",
      "   Sequence batch shape: torch.Size([8, 512])\n",
      "   Labels batch shape: torch.Size([8, 26125])\n",
      "   Sample sequence (first 20 tokens): tensor([13,  1, 14, 11, 13, 12, 12, 12, 12, 14, 12, 14,  6, 17, 17, 14, 17, 11,\n",
      "         7,  7])\n",
      "   Sample labels (non-zero count): 1\n"
     ]
    }
   ],
   "source": [
    "# Create dataset and data loaders\n",
    "print(\"üì¶ Creating training dataset...\")\n",
    "\n",
    "# Update the ProteinDataset class to work with our data\n",
    "class ProteinFunctionDataset(Dataset):\n",
    "    def __init__(self, sequences, labels, max_length=512):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Create amino acid vocabulary\n",
    "        self.aa_vocab = {\n",
    "            'A': 1, 'R': 2, 'N': 3, 'D': 4, 'C': 5, 'Q': 6, 'E': 7, 'G': 8,\n",
    "            'H': 9, 'I': 10, 'L': 11, 'K': 12, 'M': 13, 'F': 14, 'P': 15, 'S': 16,\n",
    "            'T': 17, 'W': 18, 'Y': 19, 'V': 20, '<PAD>': 0, '<UNK>': 21\n",
    "        }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        labels = self.labels[idx]\n",
    "        \n",
    "        # Convert sequence to indices\n",
    "        seq_indices = [self.aa_vocab.get(aa, self.aa_vocab['<UNK>']) for aa in sequence]\n",
    "        \n",
    "        # Truncate or pad sequence\n",
    "        if len(seq_indices) > self.max_length:\n",
    "            seq_indices = seq_indices[:self.max_length]\n",
    "        else:\n",
    "            seq_indices += [self.aa_vocab['<PAD>']] * (self.max_length - len(seq_indices))\n",
    "        \n",
    "        return torch.tensor(seq_indices, dtype=torch.long), torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# Split data into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data (80% train, 20% validation)\n",
    "train_seqs, val_seqs, train_labs, val_labs = train_test_split(\n",
    "    train_sequences_list, train_labels_array, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=None  # Can't stratify with multi-label\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(train_seqs)} proteins\")\n",
    "print(f\"Validation set: {len(val_seqs)} proteins\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ProteinFunctionDataset(train_seqs, train_labs, max_length=512)\n",
    "val_dataset = ProteinFunctionDataset(val_seqs, val_labs, max_length=512)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 8  # Small batch size for CPU training\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"üìä Data loaders created:\")\n",
    "print(f\"   Training batches: {len(train_loader)}\")\n",
    "print(f\"   Validation batches: {len(val_loader)}\")\n",
    "print(f\"   Batch size: {batch_size}\")\n",
    "\n",
    "# Test the data loader\n",
    "print(\"\\nüß™ Testing data loader...\")\n",
    "sample_batch = next(iter(train_loader))\n",
    "sequences_batch, labels_batch = sample_batch\n",
    "print(f\"   Sequence batch shape: {sequences_batch.shape}\")\n",
    "print(f\"   Labels batch shape: {labels_batch.shape}\")\n",
    "print(f\"   Sample sequence (first 20 tokens): {sequences_batch[0][:20]}\")\n",
    "print(f\"   Sample labels (non-zero count): {labels_batch[0].sum().item():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d4f42be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Setting up training components...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'code_framelocals_names' from 'torch._C._dynamo.eval_frame' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m criterion = nn.BCELoss()  \u001b[38;5;66;03m# Since our model outputs sigmoid\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Optimizer with learning rate scheduling\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m optimizer = \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\u001b[33m'\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m3\u001b[39m, factor=\u001b[32m0.5\u001b[39m, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Metrics for evaluation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\optim\\adam.py:99\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[39m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m betas[\u001b[32m1\u001b[39m].numel() != \u001b[32m1\u001b[39m:\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor betas[1] must be 1-element\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m defaults = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     88\u001b[39m     lr=lr,\n\u001b[32m     89\u001b[39m     betas=betas,\n\u001b[32m     90\u001b[39m     eps=eps,\n\u001b[32m     91\u001b[39m     weight_decay=weight_decay,\n\u001b[32m     92\u001b[39m     amsgrad=amsgrad,\n\u001b[32m     93\u001b[39m     maximize=maximize,\n\u001b[32m     94\u001b[39m     foreach=foreach,\n\u001b[32m     95\u001b[39m     capturable=capturable,\n\u001b[32m     96\u001b[39m     differentiable=differentiable,\n\u001b[32m     97\u001b[39m     fused=fused,\n\u001b[32m     98\u001b[39m     decoupled_weight_decay=decoupled_weight_decay,\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m )\n\u001b[32m    100\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(params, defaults)\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fused:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\optim\\optimizer.py:377\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, params, defaults)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:  \u001b[38;5;66;03m# noqa: D105\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    378\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdefaults\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.defaults,\n\u001b[32m    379\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.state,\n\u001b[32m    380\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mparam_groups\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.param_groups,\n\u001b[32m    381\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_compile.py:27\u001b[39m, in \u001b[36minner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;129m@overload\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_disable_dynamo\u001b[39m(\n\u001b[32m     23\u001b[39m     fn: Literal[\u001b[38;5;28;01mNone\u001b[39;00m] = \u001b[38;5;28;01mNone\u001b[39;00m, recursive: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     24\u001b[39m ) -> Callable[[Callable[_P, _T]], Callable[_P, _T]]: ...\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_disable_dynamo\u001b[39m(\n\u001b[32m     28\u001b[39m     fn: Optional[Callable[_P, _T]] = \u001b[38;5;28;01mNone\u001b[39;00m, recursive: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     29\u001b[39m ) -> Union[Callable[_P, _T], Callable[[Callable[_P, _T]], Callable[_P, _T]]]:\n\u001b[32m     30\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03m    This API should be only used inside torch, external users should still use\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m    torch._dynamo.disable. The main goal of this API is to avoid circular\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[33;03m    the invocation of the decorated function.\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, eval_frame, resume_execution\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:57\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_shapes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m guard_bool\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cache_method\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     58\u001b[39m     config,\n\u001b[32m     59\u001b[39m     exc,\n\u001b[32m     60\u001b[39m     graph_break_hints,\n\u001b[32m     61\u001b[39m     logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging,\n\u001b[32m     62\u001b[39m     trace_rules,\n\u001b[32m     63\u001b[39m     variables,\n\u001b[32m     64\u001b[39m )\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     66\u001b[39m     get_indexof,\n\u001b[32m     67\u001b[39m     JUMP_OPNAMES,\n\u001b[32m     68\u001b[39m     livevars_analysis,\n\u001b[32m     69\u001b[39m     propagate_line_nums,\n\u001b[32m     70\u001b[39m )\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     72\u001b[39m     cleaned_instructions,\n\u001b[32m     73\u001b[39m     create_call_function,\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     unique_id,\n\u001b[32m     81\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py:32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresume_execution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TORCH_DYNAMO_RESUME_IN_PREFIX\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getfile, hashable, NP_SUPPORTED_MODULES, unwrap_if_wrapper\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     33\u001b[39m     BuiltinVariable,\n\u001b[32m     34\u001b[39m     FunctionalCallVariable,\n\u001b[32m     35\u001b[39m     FunctorchHigherOrderVariable,\n\u001b[32m     36\u001b[39m     LocalGeneratorFunctionVariable,\n\u001b[32m     37\u001b[39m     LocalGeneratorObjectVariable,\n\u001b[32m     38\u001b[39m     NestedUserFunctionVariable,\n\u001b[32m     39\u001b[39m     PolyfilledFunctionVariable,\n\u001b[32m     40\u001b[39m     SkipFunctionVariable,\n\u001b[32m     41\u001b[39m     TorchInGraphFunctionVariable,\n\u001b[32m     42\u001b[39m     UserFunctionVariable,\n\u001b[32m     43\u001b[39m     UserMethodVariable,\n\u001b[32m     44\u001b[39m )\n\u001b[32m     47\u001b[39m np: Optional[types.ModuleType] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_dynamo\\variables\\__init__.py:19\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThis package implements variable tracking and symbolic execution capabilities for Dynamo,\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mwhich are essential for converting Python code into FX graphs. It provides a comprehensive\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33;03mallows Dynamo to accurately trace and optimize Python code while preserving its semantics.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuiltin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BuiltinVariable\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable, EnumVariable\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_dynamo\\variables\\base.py:26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcurrent_scope_id\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m current_scope_id\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m unimplemented, unimplemented_v2\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GuardBuilder, install_guard\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AttrSource, Source\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cmp_name_to_op_mapping, istype\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_dynamo\\guards.py:46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moverrides\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_device\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meval_frame\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m code_framelocals_names\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     48\u001b[39m     check_obj_id,\n\u001b[32m     49\u001b[39m     check_type_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m     RootGuardManager,\n\u001b[32m     58\u001b[39m )\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     60\u001b[39m     IndexedSource,\n\u001b[32m     61\u001b[39m     is_from_flatten_script_object_source,\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m     TensorPropertySource,\n\u001b[32m     66\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'code_framelocals_names' from 'torch._C._dynamo.eval_frame' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Set up training components\n",
    "print(\"üîß Setting up training components...\")\n",
    "\n",
    "# Loss function for multi-label classification\n",
    "# Using Binary Cross Entropy with Logits for numerical stability\n",
    "criterion = nn.BCELoss()  # Since our model outputs sigmoid\n",
    "\n",
    "# Optimizer with learning rate scheduling\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
    "\n",
    "# Metrics for evaluation\n",
    "def calculate_metrics(y_true, y_pred, threshold=0.5):\n",
    "    \"\"\"Calculate evaluation metrics for multi-label classification\"\"\"\n",
    "    y_pred_binary = (y_pred > threshold).float()\n",
    "    \n",
    "    # Precision, Recall, F1 (micro-average)\n",
    "    tp = (y_true * y_pred_binary).sum()\n",
    "    fp = ((1 - y_true) * y_pred_binary).sum()\n",
    "    fn = (y_true * (1 - y_pred_binary)).sum()\n",
    "    \n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    \n",
    "    return precision.item(), recall.item(), f1.item()\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for batch_idx, (sequences, labels) in enumerate(tqdm(loader, desc=\"Training\")):\n",
    "        sequences, labels = sequences.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        all_preds.append(outputs.detach().cpu())\n",
    "        all_labels.append(labels.detach().cpu())\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Batch {batch_idx}/{len(loader)}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Calculate epoch metrics\n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    precision, recall, f1 = calculate_metrics(all_labels, all_preds)\n",
    "    \n",
    "    return total_loss / len(loader), precision, recall, f1\n",
    "\n",
    "# Validation function\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in tqdm(loader, desc=\"Validation\"):\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            all_preds.append(outputs.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    precision, recall, f1 = calculate_metrics(all_labels, all_preds)\n",
    "    \n",
    "    return total_loss / len(loader), precision, recall, f1\n",
    "\n",
    "print(\"‚úÖ Training components ready!\")\n",
    "print(f\"üìä Training will run on: {device}\")\n",
    "print(f\"üéØ Optimizer: {optimizer.__class__.__name__}\")\n",
    "print(f\"üìâ Loss function: {criterion.__class__.__name__}\")\n",
    "print(f\"üìà Scheduler: {scheduler.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae76d254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Restarting with basic PyTorch setup...\n",
      "üîß Setting up training components...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'code_framelocals_names' from 'torch._C._dynamo.eval_frame' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m criterion = nn.BCELoss()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Simple optimizer setup to avoid the import error\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m optimizer = \u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Basic scheduler\u001b[39;00m\n\u001b[32m     19\u001b[39m scheduler = StepLR(optimizer, step_size=\u001b[32m5\u001b[39m, gamma=\u001b[32m0.5\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\optim\\adam.py:99\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[39m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m betas[\u001b[32m1\u001b[39m].numel() != \u001b[32m1\u001b[39m:\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTensor betas[1] must be 1-element\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     87\u001b[39m defaults = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     88\u001b[39m     lr=lr,\n\u001b[32m     89\u001b[39m     betas=betas,\n\u001b[32m     90\u001b[39m     eps=eps,\n\u001b[32m     91\u001b[39m     weight_decay=weight_decay,\n\u001b[32m     92\u001b[39m     amsgrad=amsgrad,\n\u001b[32m     93\u001b[39m     maximize=maximize,\n\u001b[32m     94\u001b[39m     foreach=foreach,\n\u001b[32m     95\u001b[39m     capturable=capturable,\n\u001b[32m     96\u001b[39m     differentiable=differentiable,\n\u001b[32m     97\u001b[39m     fused=fused,\n\u001b[32m     98\u001b[39m     decoupled_weight_decay=decoupled_weight_decay,\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m )\n\u001b[32m    100\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(params, defaults)\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fused:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\optim\\optimizer.py:377\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, params, defaults)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:  \u001b[38;5;66;03m# noqa: D105\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    378\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdefaults\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.defaults,\n\u001b[32m    379\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.state,\n\u001b[32m    380\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mparam_groups\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.param_groups,\n\u001b[32m    381\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_compile.py:27\u001b[39m, in \u001b[36minner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;129m@overload\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_disable_dynamo\u001b[39m(\n\u001b[32m     23\u001b[39m     fn: Literal[\u001b[38;5;28;01mNone\u001b[39;00m] = \u001b[38;5;28;01mNone\u001b[39;00m, recursive: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     24\u001b[39m ) -> Callable[[Callable[_P, _T]], Callable[_P, _T]]: ...\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_disable_dynamo\u001b[39m(\n\u001b[32m     28\u001b[39m     fn: Optional[Callable[_P, _T]] = \u001b[38;5;28;01mNone\u001b[39;00m, recursive: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     29\u001b[39m ) -> Union[Callable[_P, _T], Callable[[Callable[_P, _T]], Callable[_P, _T]]]:\n\u001b[32m     30\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03m    This API should be only used inside torch, external users should still use\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m    torch._dynamo.disable. The main goal of this API is to avoid circular\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m \u001b[33;03m    the invocation of the decorated function.\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config, convert_frame, eval_frame, resume_execution\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:52\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:57\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_shapes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m guard_bool\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_functools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cache_method\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     58\u001b[39m     config,\n\u001b[32m     59\u001b[39m     exc,\n\u001b[32m     60\u001b[39m     graph_break_hints,\n\u001b[32m     61\u001b[39m     logging \u001b[38;5;28;01mas\u001b[39;00m torchdynamo_logging,\n\u001b[32m     62\u001b[39m     trace_rules,\n\u001b[32m     63\u001b[39m     variables,\n\u001b[32m     64\u001b[39m )\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_analysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     66\u001b[39m     get_indexof,\n\u001b[32m     67\u001b[39m     JUMP_OPNAMES,\n\u001b[32m     68\u001b[39m     livevars_analysis,\n\u001b[32m     69\u001b[39m     propagate_line_nums,\n\u001b[32m     70\u001b[39m )\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbytecode_transformation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     72\u001b[39m     cleaned_instructions,\n\u001b[32m     73\u001b[39m     create_call_function,\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     unique_id,\n\u001b[32m     81\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py:32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresume_execution\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TORCH_DYNAMO_RESUME_IN_PREFIX\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getfile, hashable, NP_SUPPORTED_MODULES, unwrap_if_wrapper\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     33\u001b[39m     BuiltinVariable,\n\u001b[32m     34\u001b[39m     FunctionalCallVariable,\n\u001b[32m     35\u001b[39m     FunctorchHigherOrderVariable,\n\u001b[32m     36\u001b[39m     LocalGeneratorFunctionVariable,\n\u001b[32m     37\u001b[39m     LocalGeneratorObjectVariable,\n\u001b[32m     38\u001b[39m     NestedUserFunctionVariable,\n\u001b[32m     39\u001b[39m     PolyfilledFunctionVariable,\n\u001b[32m     40\u001b[39m     SkipFunctionVariable,\n\u001b[32m     41\u001b[39m     TorchInGraphFunctionVariable,\n\u001b[32m     42\u001b[39m     UserFunctionVariable,\n\u001b[32m     43\u001b[39m     UserMethodVariable,\n\u001b[32m     44\u001b[39m )\n\u001b[32m     47\u001b[39m np: Optional[types.ModuleType] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_dynamo\\variables\\__init__.py:19\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThis package implements variable tracking and symbolic execution capabilities for Dynamo,\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mwhich are essential for converting Python code into FX graphs. It provides a comprehensive\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m \u001b[33;03mallows Dynamo to accurately trace and optimize Python code while preserving its semantics.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbuiltin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BuiltinVariable\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable, EnumVariable\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_dynamo\\variables\\base.py:26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcurrent_scope_id\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m current_scope_id\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m unimplemented, unimplemented_v2\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GuardBuilder, install_guard\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AttrSource, Source\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cmp_name_to_op_mapping, istype\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\_dynamo\\guards.py:46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moverrides\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_device\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meval_frame\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m code_framelocals_names\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mguards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     48\u001b[39m     check_obj_id,\n\u001b[32m     49\u001b[39m     check_type_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m     RootGuardManager,\n\u001b[32m     58\u001b[39m )\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msource\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     60\u001b[39m     IndexedSource,\n\u001b[32m     61\u001b[39m     is_from_flatten_script_object_source,\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m     TensorPropertySource,\n\u001b[32m     66\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'code_framelocals_names' from 'torch._C._dynamo.eval_frame' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Restart imports and use basic PyTorch components\n",
    "print(\"üîß Restarting with basic PyTorch setup...\")\n",
    "\n",
    "# Re-import essential components\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Set up training components with basic imports\n",
    "print(\"üîß Setting up training components...\")\n",
    "\n",
    "# Loss function for multi-label classification\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Simple optimizer setup to avoid the import error\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Basic scheduler\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "print(\"‚úÖ Training components ready!\")\n",
    "print(f\"üìä Training will run on: {device}\")\n",
    "print(f\"üéØ Loss function: Binary Cross Entropy\")\n",
    "print(f\"üéØ Optimizer: Adam with lr=0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a843d8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Creating simple training setup...\n",
      "‚úÖ Simple training setup ready!\n",
      "üöÄ Ready to start training the protein function prediction model!\n",
      "üìä Training on: cpu\n",
      "üéØ Dataset size: 4000 training, 1000 validation samples\n"
     ]
    }
   ],
   "source": [
    "# Create a simple training loop without problematic PyTorch optimizers\n",
    "print(\"üîß Creating simple training setup...\")\n",
    "\n",
    "# Manual parameter updates (basic SGD)\n",
    "def simple_sgd_step(model, learning_rate=0.001):\n",
    "    \"\"\"Simple SGD parameter update\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            if param.grad is not None:\n",
    "                param -= learning_rate * param.grad\n",
    "\n",
    "# Simple evaluation metric\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in val_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            outputs = model(sequences)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * sequences.size(0)\n",
    "            total_samples += sequences.size(0)\n",
    "            \n",
    "            # Count correct predictions (threshold at 0.5)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct_predictions += ((predicted == labels).float().mean(dim=1) == 1.0).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Simple training function\n",
    "def train_simple_epoch(model, train_loader, device, learning_rate=0.001):\n",
    "    \"\"\"Train one epoch with simple parameter updates\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    for batch_idx, (sequences, labels) in enumerate(train_loader):\n",
    "        sequences, labels = sequences.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Simple SGD update\n",
    "        simple_sgd_step(model, learning_rate)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f\"  Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "print(\"‚úÖ Simple training setup ready!\")\n",
    "print(\"üöÄ Ready to start training the protein function prediction model!\")\n",
    "print(f\"üìä Training on: {device}\")\n",
    "print(f\"üéØ Dataset size: {len(train_dataset)} training, {len(val_dataset)} validation samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "695be37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training...\n",
      "üìä Training configuration:\n",
      "   Epochs: 3\n",
      "   Learning rate: 0.001\n",
      "   Batch size: 8\n",
      "   Device: cpu\n",
      "\n",
      "üîÑ Epoch 1/3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [256, 256, 5], expected input[8, 128, 512] to have 256 channels, but got 128 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m train_loss = \u001b[43mtrain_simple_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m train_losses.append(train_loss)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Validation\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mtrain_simple_epoch\u001b[39m\u001b[34m(model, train_loader, device, learning_rate)\u001b[39m\n\u001b[32m     50\u001b[39m sequences, labels = sequences.to(device), labels.to(device)\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36m_wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m         tracing_state.push_scope(name)\n\u001b[32m   1738\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m         recording_scopes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1740\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1741\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.forward(*\u001b[38;5;28minput\u001b[39m, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36m_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1748\u001b[39m     if self._compiled_call_impl is not None:\n\u001b[32m   1749\u001b[39m         return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     else:\n\u001b[32m   1751\u001b[39m         return self._call_impl(*args, **kwargs)\n\u001b[32m   1753\u001b[39m # torchrec tests the code consistency with the following code\n\u001b[32m   1754\u001b[39m # fmt: off\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mProteinFunctionPredictor.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Convolutional layers for different kernel sizes\u001b[39;00m\n\u001b[32m     59\u001b[39m conv_out1 = \u001b[38;5;28mself\u001b[39m.relu(\u001b[38;5;28mself\u001b[39m.conv1(embedded))\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m conv_out2 = \u001b[38;5;28mself\u001b[39m.relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     61\u001b[39m conv_out3 = \u001b[38;5;28mself\u001b[39m.relu(\u001b[38;5;28mself\u001b[39m.conv3(embedded))\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Concatenate conv outputs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36m_wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m         tracing_state.push_scope(name)\n\u001b[32m   1738\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m         recording_scopes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1740\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1741\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.forward(*\u001b[38;5;28minput\u001b[39m, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36m_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1748\u001b[39m     if self._compiled_call_impl is not None:\n\u001b[32m   1749\u001b[39m         return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     else:\n\u001b[32m   1751\u001b[39m         return self._call_impl(*args, **kwargs)\n\u001b[32m   1753\u001b[39m # torchrec tests the code consistency with the following code\n\u001b[32m   1754\u001b[39m # fmt: off\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:375\u001b[39m, in \u001b[36mConv1d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:370\u001b[39m, in \u001b[36mConv1d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv1d(\n\u001b[32m    360\u001b[39m         F.pad(\n\u001b[32m    361\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    369\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Given groups=1, weight of size [256, 256, 5], expected input[8, 128, 512] to have 256 channels, but got 128 channels instead"
     ]
    }
   ],
   "source": [
    "# Start training the protein function prediction model\n",
    "print(\"üöÄ Starting training...\")\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 3  # Start with fewer epochs for initial testing\n",
    "learning_rate = 0.001\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Training history\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "print(f\"üìä Training configuration:\")\n",
    "print(f\"   Epochs: {num_epochs}\")\n",
    "print(f\"   Learning rate: {learning_rate}\")\n",
    "print(f\"   Batch size: {batch_size}\")\n",
    "print(f\"   Device: {device}\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nüîÑ Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Training\n",
    "    train_loss = train_simple_epoch(model, train_loader, device, learning_rate)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_accuracy = evaluate_model(model, val_loader, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    print(f\"üìä Epoch {epoch+1} Results:\")\n",
    "    print(f\"   Training Loss: {train_loss:.4f}\")\n",
    "    print(f\"   Validation Loss: {val_loss:.4f}\")\n",
    "    print(f\"   Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print(f\"‚úÖ New best validation loss: {best_val_loss:.4f}\")\n",
    "        # In a real scenario, you would save the model here\n",
    "        # torch.save(model.state_dict(), 'best_protein_model.pth')\n",
    "\n",
    "print(\"\\nüéâ Training completed!\")\n",
    "print(f\"üèÜ Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"üìà Final validation accuracy: {val_accuracies[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f20785be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Fixing model architecture...\n",
      "üèóÔ∏è  Creating fixed model...\n",
      "üìä Fixed Model Statistics:\n",
      "   Total parameters: 1,270,029\n",
      "   Model size: ~5.1 MB\n",
      "\n",
      "üß™ Testing model forward pass...\n",
      "‚úÖ Forward pass successful!\n",
      "   Input shape: torch.Size([2, 512])\n",
      "   Output shape: torch.Size([2, 26125])\n",
      "   Output range: [0.4926, 0.5073]\n",
      "‚úÖ Forward pass successful!\n",
      "   Input shape: torch.Size([2, 512])\n",
      "   Output shape: torch.Size([2, 26125])\n",
      "   Output range: [0.4926, 0.5073]\n"
     ]
    }
   ],
   "source": [
    "# Fix the model architecture - there was a dimension mismatch\n",
    "print(\"üîß Fixing model architecture...\")\n",
    "\n",
    "class ProteinFunctionPredictorFixed(nn.Module):\n",
    "    def __init__(self, vocab_size=22, embedding_dim=128, hidden_dim=256, num_classes=26125, max_length=512, dropout=0.3):\n",
    "        super(ProteinFunctionPredictorFixed, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Embedding layer for amino acids\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # Convolutional layers for local pattern detection (fixed input/output dimensions)\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=5, padding=2)  # Fixed: input should be embedding_dim\n",
    "        self.conv3 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=7, padding=3)  # Fixed: input should be embedding_dim\n",
    "        \n",
    "        # Combine conv outputs\n",
    "        self.conv_combine = nn.Conv1d(hidden_dim * 3, hidden_dim, kernel_size=1)\n",
    "        \n",
    "        # Bidirectional LSTM for sequence modeling\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim//2, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        # Global pooling and classification layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim//2)\n",
    "        self.fc2 = nn.Linear(hidden_dim//2, hidden_dim//4)\n",
    "        self.classifier = nn.Linear(hidden_dim//4, num_classes)\n",
    "        \n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize model weights\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "            elif isinstance(module, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(module.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        \n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_len, embedding_dim)\n",
    "        embedded = embedded.transpose(1, 2)  # (batch_size, embedding_dim, seq_len)\n",
    "        \n",
    "        # Convolutional layers for different kernel sizes\n",
    "        conv_out1 = self.relu(self.conv1(embedded))\n",
    "        conv_out2 = self.relu(self.conv2(embedded))\n",
    "        conv_out3 = self.relu(self.conv3(embedded))\n",
    "        \n",
    "        # Concatenate conv outputs\n",
    "        conv_concat = torch.cat([conv_out1, conv_out2, conv_out3], dim=1)  # (batch_size, hidden_dim*3, seq_len)\n",
    "        conv_combined = self.relu(self.conv_combine(conv_concat))  # (batch_size, hidden_dim, seq_len)\n",
    "        conv_combined = conv_combined.transpose(1, 2)  # (batch_size, seq_len, hidden_dim)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, (hidden, cell) = self.lstm(conv_combined)  # (batch_size, seq_len, hidden_dim)\n",
    "        \n",
    "        # Global max pooling\n",
    "        pooled = torch.max(lstm_out, dim=1)[0]  # (batch_size, hidden_dim)\n",
    "        \n",
    "        # Classification layers\n",
    "        x = self.dropout(pooled)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        output = self.sigmoid(self.classifier(x))  # Multi-label classification\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Create new model with fixed architecture\n",
    "print(\"üèóÔ∏è  Creating fixed model...\")\n",
    "model = ProteinFunctionPredictorFixed(\n",
    "    vocab_size=22,\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=128,  # Reduced for CPU efficiency\n",
    "    num_classes=len(all_go_terms),\n",
    "    max_length=512,\n",
    "    dropout=0.3\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"üìä Fixed Model Statistics:\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Model size: ~{total_params * 4 / 1e6:.1f} MB\")\n",
    "\n",
    "# Test forward pass\n",
    "print(\"\\nüß™ Testing model forward pass...\")\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randint(0, 22, (2, 512)).to(device)\n",
    "    test_output = model(test_input)\n",
    "    print(f\"‚úÖ Forward pass successful!\")\n",
    "    print(f\"   Input shape: {test_input.shape}\")\n",
    "    print(f\"   Output shape: {test_output.shape}\")\n",
    "    print(f\"   Output range: [{test_output.min():.4f}, {test_output.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b68e53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training with fixed model...\n",
      "üìä Training configuration:\n",
      "   Epochs: 2\n",
      "   Learning rate: 0.0005\n",
      "   Batch size: 8\n",
      "   Device: cpu\n",
      "\n",
      "üîÑ Epoch 1/2\n",
      "--------------------------------------------------\n",
      "  Batch 0/500, Loss: 0.6932\n",
      "  Batch 50/500, Loss: 0.6932\n",
      "  Batch 100/500, Loss: 0.6932\n",
      "  Batch 150/500, Loss: 0.6932\n",
      "  Batch 200/500, Loss: 0.6932\n",
      "  Batch 250/500, Loss: 0.6932\n",
      "  Batch 300/500, Loss: 0.6931\n",
      "  Batch 350/500, Loss: 0.6932\n",
      "  Batch 400/500, Loss: 0.6932\n",
      "  Batch 450/500, Loss: 0.6932\n",
      "üìä Epoch 1 Results:\n",
      "   Training Loss: 0.6932\n",
      "   Validation Loss: 0.6932\n",
      "   Validation Accuracy: 0.0000\n",
      "‚úÖ New best validation loss: 0.6932\n",
      "\n",
      "üîÑ Epoch 2/2\n",
      "--------------------------------------------------\n",
      "  Batch 0/500, Loss: 0.6932\n",
      "  Batch 50/500, Loss: 0.6932\n",
      "  Batch 100/500, Loss: 0.6932\n",
      "  Batch 150/500, Loss: 0.6932\n",
      "  Batch 200/500, Loss: 0.6932\n",
      "  Batch 250/500, Loss: 0.6931\n",
      "  Batch 300/500, Loss: 0.6931\n",
      "  Batch 350/500, Loss: 0.6932\n",
      "  Batch 400/500, Loss: 0.6932\n",
      "  Batch 450/500, Loss: 0.6931\n",
      "üìä Epoch 2 Results:\n",
      "   Training Loss: 0.6932\n",
      "   Validation Loss: 0.6931\n",
      "   Validation Accuracy: 0.0000\n",
      "‚úÖ New best validation loss: 0.6931\n",
      "\n",
      "üéâ Training completed!\n",
      "üèÜ Best validation loss: 0.6931\n",
      "üìà Final validation accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Training summary complete!\n"
     ]
    }
   ],
   "source": [
    "# Train the fixed model\n",
    "print(\"üöÄ Starting training with fixed model...\")\n",
    "\n",
    "# Training hyperparameters\n",
    "num_epochs = 2  # Start with just 2 epochs for demonstration\n",
    "learning_rate = 0.0005  # Slightly lower learning rate\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Training history\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "print(f\"üìä Training configuration:\")\n",
    "print(f\"   Epochs: {num_epochs}\")\n",
    "print(f\"   Learning rate: {learning_rate}\")\n",
    "print(f\"   Batch size: {batch_size}\")\n",
    "print(f\"   Device: {device}\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nüîÑ Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Training\n",
    "    train_loss = train_simple_epoch(model, train_loader, device, learning_rate)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_accuracy = evaluate_model(model, val_loader, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    print(f\"üìä Epoch {epoch+1} Results:\")\n",
    "    print(f\"   Training Loss: {train_loss:.4f}\")\n",
    "    print(f\"   Validation Loss: {val_loss:.4f}\")\n",
    "    print(f\"   Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print(f\"‚úÖ New best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "print(\"\\nüéâ Training completed!\")\n",
    "print(f\"üèÜ Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"üìà Final validation accuracy: {val_accuracies[-1]:.4f}\")\n",
    "\n",
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, len(train_losses)+1), train_losses, 'b-', label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses)+1), val_losses, 'r-', label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(val_accuracies)+1), val_accuracies, 'g-', label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Training summary complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "961ffe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Preparing predictions and submission...\n",
      "üìÇ Loading test sequences...\n",
      "Loaded 1000 sequences...\n",
      "Loaded 2000 sequences...\n",
      "Loaded 3000 sequences...\n",
      "Loaded 4000 sequences...\n",
      "Loaded 5000 sequences...\n",
      "Loaded 6000 sequences...\n",
      "Loaded 7000 sequences...\n",
      "Loaded 8000 sequences...\n",
      "Loaded 9000 sequences...\n",
      "Loaded 10000 sequences...\n",
      "Loaded 11000 sequences...\n",
      "Loaded 12000 sequences...\n",
      "Loaded 13000 sequences...\n",
      "Loaded 14000 sequences...\n",
      "Loaded 15000 sequences...\n",
      "Loaded 16000 sequences...\n",
      "Loaded 17000 sequences...\n",
      "Loaded 18000 sequences...\n",
      "Loaded 19000 sequences...\n",
      "Loaded 20000 sequences...\n",
      "Loaded 21000 sequences...\n",
      "Loaded 22000 sequences...\n",
      "Loaded 23000 sequences...\n",
      "Loaded 24000 sequences...\n",
      "Loaded 25000 sequences...\n",
      "Loaded 26000 sequences...\n",
      "Loaded 27000 sequences...\n",
      "Loaded 28000 sequences...\n",
      "Loaded 29000 sequences...\n",
      "Loaded 30000 sequences...\n",
      "Loaded 31000 sequences...\n",
      "Loaded 32000 sequences...\n",
      "Loaded 33000 sequences...\n",
      "Loaded 34000 sequences...\n",
      "Loaded 35000 sequences...\n",
      "Loaded 36000 sequences...\n",
      "Loaded 37000 sequences...\n",
      "Loaded 38000 sequences...\n",
      "Loaded 39000 sequences...\n",
      "Loaded 40000 sequences...\n",
      "Loaded 41000 sequences...\n",
      "Loaded 42000 sequences...\n",
      "Loaded 43000 sequences...\n",
      "Loaded 44000 sequences...\n",
      "Loaded 45000 sequences...\n",
      "Loaded 46000 sequences...\n",
      "Loaded 47000 sequences...\n",
      "Loaded 48000 sequences...\n",
      "Loaded 49000 sequences...\n",
      "Loaded 50000 sequences...\n",
      "Loaded 51000 sequences...\n",
      "Loaded 52000 sequences...\n",
      "Loaded 53000 sequences...\n",
      "Loaded 54000 sequences...\n",
      "Loaded 55000 sequences...\n",
      "Loaded 56000 sequences...\n",
      "Loaded 57000 sequences...\n",
      "Loaded 58000 sequences...\n",
      "Loaded 59000 sequences...\n",
      "Loaded 60000 sequences...\n",
      "Loaded 61000 sequences...\n",
      "Loaded 62000 sequences...\n",
      "Loaded 63000 sequences...\n",
      "Loaded 64000 sequences...\n",
      "Loaded 65000 sequences...\n",
      "Loaded 66000 sequences...\n",
      "Loaded 67000 sequences...\n",
      "Loaded 68000 sequences...\n",
      "Loaded 69000 sequences...\n",
      "Loaded 70000 sequences...\n",
      "Loaded 71000 sequences...\n",
      "Loaded 72000 sequences...\n",
      "Loaded 73000 sequences...\n",
      "Loaded 74000 sequences...\n",
      "Loaded 75000 sequences...\n",
      "Loaded 76000 sequences...\n",
      "Loaded 77000 sequences...\n",
      "Loaded 78000 sequences...\n",
      "Loaded 79000 sequences...\n",
      "Loaded 80000 sequences...\n",
      "Loaded 81000 sequences...\n",
      "Loaded 82000 sequences...\n",
      "Loaded 83000 sequences...\n",
      "Loaded 84000 sequences...\n",
      "Loaded 85000 sequences...\n",
      "Loaded 86000 sequences...\n",
      "Loaded 87000 sequences...\n",
      "Loaded 88000 sequences...\n",
      "Loaded 89000 sequences...\n",
      "Loaded 90000 sequences...\n",
      "Loaded 91000 sequences...\n",
      "Loaded 92000 sequences...\n",
      "Loaded 93000 sequences...\n",
      "Loaded 94000 sequences...\n",
      "Loaded 95000 sequences...\n",
      "Loaded 96000 sequences...\n",
      "Loaded 97000 sequences...\n",
      "Loaded 98000 sequences...\n",
      "Loaded 99000 sequences...\n",
      "Loaded 100000 sequences...\n",
      "Loaded 101000 sequences...\n",
      "Loaded 102000 sequences...\n",
      "Loaded 103000 sequences...\n",
      "Loaded 104000 sequences...\n",
      "Loaded 105000 sequences...\n",
      "Loaded 106000 sequences...\n",
      "Loaded 107000 sequences...\n",
      "Loaded 108000 sequences...\n",
      "Loaded 109000 sequences...\n",
      "Loaded 110000 sequences...\n",
      "Loaded 111000 sequences...\n",
      "Loaded 112000 sequences...\n",
      "Loaded 113000 sequences...\n",
      "Loaded 114000 sequences...\n",
      "Loaded 115000 sequences...\n",
      "Loaded 116000 sequences...\n",
      "Loaded 117000 sequences...\n",
      "Loaded 118000 sequences...\n",
      "Loaded 119000 sequences...\n",
      "Loaded 120000 sequences...\n",
      "Loaded 121000 sequences...\n",
      "Loaded 122000 sequences...\n",
      "Loaded 123000 sequences...\n",
      "Loaded 124000 sequences...\n",
      "Loaded 125000 sequences...\n",
      "Loaded 126000 sequences...\n",
      "Loaded 127000 sequences...\n",
      "Loaded 128000 sequences...\n",
      "Loaded 129000 sequences...\n",
      "Loaded 130000 sequences...\n",
      "Loaded 131000 sequences...\n",
      "Loaded 132000 sequences...\n",
      "Loaded 133000 sequences...\n",
      "Loaded 134000 sequences...\n",
      "Loaded 135000 sequences...\n",
      "Loaded 136000 sequences...\n",
      "Loaded 137000 sequences...\n",
      "Loaded 138000 sequences...\n",
      "Loaded 139000 sequences...\n",
      "Loaded 140000 sequences...\n",
      "Loaded 141000 sequences...\n",
      "Loaded 142000 sequences...\n",
      "Loaded 143000 sequences...\n",
      "Loaded 144000 sequences...\n",
      "Loaded 145000 sequences...\n",
      "Loaded 146000 sequences...\n",
      "Loaded 147000 sequences...\n",
      "Loaded 148000 sequences...\n",
      "Loaded 149000 sequences...\n",
      "Loaded 150000 sequences...\n",
      "Loaded 151000 sequences...\n",
      "Loaded 152000 sequences...\n",
      "Loaded 153000 sequences...\n",
      "Loaded 154000 sequences...\n",
      "Loaded 155000 sequences...\n",
      "Loaded 156000 sequences...\n",
      "Loaded 157000 sequences...\n",
      "Loaded 158000 sequences...\n",
      "Loaded 159000 sequences...\n",
      "Loaded 160000 sequences...\n",
      "Loaded 161000 sequences...\n",
      "Loaded 162000 sequences...\n",
      "Loaded 163000 sequences...\n",
      "Loaded 164000 sequences...\n",
      "Loaded 165000 sequences...\n",
      "Loaded 166000 sequences...\n",
      "Loaded 167000 sequences...\n",
      "Loaded 168000 sequences...\n",
      "Loaded 169000 sequences...\n",
      "Loaded 170000 sequences...\n",
      "Loaded 171000 sequences...\n",
      "Loaded 172000 sequences...\n",
      "Loaded 173000 sequences...\n",
      "Loaded 174000 sequences...\n",
      "Loaded 175000 sequences...\n",
      "Loaded 176000 sequences...\n",
      "Loaded 177000 sequences...\n",
      "Loaded 178000 sequences...\n",
      "Loaded 179000 sequences...\n",
      "Loaded 180000 sequences...\n",
      "Loaded 181000 sequences...\n",
      "Loaded 182000 sequences...\n",
      "Loaded 183000 sequences...\n",
      "Loaded 184000 sequences...\n",
      "Loaded 185000 sequences...\n",
      "Loaded 186000 sequences...\n",
      "Loaded 187000 sequences...\n",
      "Loaded 188000 sequences...\n",
      "Loaded 189000 sequences...\n",
      "Loaded 190000 sequences...\n",
      "Loaded 191000 sequences...\n",
      "Loaded 192000 sequences...\n",
      "Loaded 193000 sequences...\n",
      "Loaded 194000 sequences...\n",
      "Loaded 195000 sequences...\n",
      "Loaded 196000 sequences...\n",
      "Loaded 197000 sequences...\n",
      "Loaded 198000 sequences...\n",
      "Loaded 199000 sequences...\n",
      "Loaded 200000 sequences...\n",
      "Loaded 201000 sequences...\n",
      "Loaded 202000 sequences...\n",
      "Loaded 203000 sequences...\n",
      "Loaded 204000 sequences...\n",
      "Loaded 205000 sequences...\n",
      "Loaded 206000 sequences...\n",
      "Loaded 207000 sequences...\n",
      "Loaded 208000 sequences...\n",
      "Loaded 209000 sequences...\n",
      "Loaded 210000 sequences...\n",
      "Loaded 211000 sequences...\n",
      "Loaded 212000 sequences...\n",
      "Loaded 213000 sequences...\n",
      "Loaded 214000 sequences...\n",
      "Loaded 215000 sequences...\n",
      "Loaded 216000 sequences...\n",
      "Loaded 217000 sequences...\n",
      "Loaded 218000 sequences...\n",
      "Loaded 219000 sequences...\n",
      "Loaded 220000 sequences...\n",
      "Loaded 221000 sequences...\n",
      "Loaded 222000 sequences...\n",
      "Loaded 223000 sequences...\n",
      "Loaded 224000 sequences...\n",
      "Total sequences loaded: 224309\n",
      "Loaded 224309 test sequences\n",
      "Test dataset created with 224309 sequences\n",
      "üîÆ Generating predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   4%|‚ñç         | 1179/28039 [02:31<57:36,  7.77it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m sequences, _ \u001b[38;5;129;01min\u001b[39;00m tqdm(test_loader, desc=\u001b[33m\"\u001b[39m\u001b[33mPredicting\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     36\u001b[39m         sequences = sequences.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m         outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m         all_predictions.append(outputs.cpu().numpy())\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Combine all predictions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36m_wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m         tracing_state.push_scope(name)\n\u001b[32m   1738\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m         recording_scopes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1740\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1741\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.forward(*\u001b[38;5;28minput\u001b[39m, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36m_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1748\u001b[39m     if self._compiled_call_impl is not None:\n\u001b[32m   1749\u001b[39m         return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     else:\n\u001b[32m   1751\u001b[39m         return self._call_impl(*args, **kwargs)\n\u001b[32m   1753\u001b[39m # torchrec tests the code consistency with the following code\n\u001b[32m   1754\u001b[39m # fmt: off\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mProteinFunctionPredictorFixed.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     68\u001b[39m conv_combined = conv_combined.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# (batch_size, seq_len, hidden_dim)\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# LSTM\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m lstm_out, (hidden, cell) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_combined\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, seq_len, hidden_dim)\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# Global max pooling\u001b[39;00m\n\u001b[32m     74\u001b[39m pooled = torch.max(lstm_out, dim=\u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# (batch_size, hidden_dim)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36m_wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m         tracing_state.push_scope(name)\n\u001b[32m   1738\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m         recording_scopes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1740\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1741\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.forward(*\u001b[38;5;28minput\u001b[39m, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36m_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1748\u001b[39m     if self._compiled_call_impl is not None:\n\u001b[32m   1749\u001b[39m         return self._compiled_call_impl(*args, **kwargs)  # type: ignore[misc]\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     else:\n\u001b[32m   1751\u001b[39m         return self._call_impl(*args, **kwargs)\n\u001b[32m   1753\u001b[39m # torchrec tests the code consistency with the following code\n\u001b[32m   1754\u001b[39m # fmt: off\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1124\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1121\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1136\u001b[39m     result = _VF.lstm(\n\u001b[32m   1137\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1138\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1145\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1146\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Create predictions and prepare submission\n",
    "print(\"üéØ Preparing predictions and submission...\")\n",
    "\n",
    "# Load test sequences\n",
    "print(\"üìÇ Loading test sequences...\")\n",
    "try:\n",
    "    test_sequences = load_sequences_batch(test_sequences_path, batch_size=1000)\n",
    "    print(f\"Loaded {len(test_sequences)} test sequences\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading test sequences: {e}\")\n",
    "    print(\"Creating dummy test data for demonstration...\")\n",
    "    # Create some dummy test sequences for demonstration\n",
    "    test_sequences = {f\"test_protein_{i}\": \"MKTFLVLSLLVSLAFEVTTHNGDTAAQR\" for i in range(10)}\n",
    "\n",
    "# Create test dataset\n",
    "test_sequence_ids = list(test_sequences.keys())\n",
    "test_sequence_data = list(test_sequences.values())\n",
    "\n",
    "# Create test dataset\n",
    "test_dataset = ProteinFunctionDataset(\n",
    "    test_sequence_data, \n",
    "    [np.zeros(len(all_go_terms), dtype=np.float32) for _ in test_sequence_data],  # Dummy labels\n",
    "    max_length=512\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Test dataset created with {len(test_dataset)} sequences\")\n",
    "\n",
    "# Generate predictions\n",
    "print(\"üîÆ Generating predictions...\")\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sequences, _ in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        sequences = sequences.to(device)\n",
    "        outputs = model(sequences)\n",
    "        all_predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "# Combine all predictions\n",
    "predictions = np.concatenate(all_predictions, axis=0)\n",
    "print(f\"Generated predictions shape: {predictions.shape}\")\n",
    "\n",
    "# Create submission file format\n",
    "print(\"üìù Creating submission file...\")\n",
    "\n",
    "# For each protein, select top GO terms above a threshold\n",
    "threshold = 0.1  # Lower threshold to ensure we get some predictions\n",
    "max_terms_per_protein = 100  # Limit predictions per protein\n",
    "\n",
    "submission_data = []\n",
    "\n",
    "for i, protein_id in enumerate(test_sequence_ids):\n",
    "    protein_predictions = predictions[i]\n",
    "    \n",
    "    # Get indices of predictions above threshold\n",
    "    above_threshold = np.where(protein_predictions > threshold)[0]\n",
    "    \n",
    "    if len(above_threshold) == 0:\n",
    "        # If no predictions above threshold, take top 5\n",
    "        above_threshold = np.argsort(protein_predictions)[-5:]\n",
    "    \n",
    "    # Sort by prediction score (descending)\n",
    "    sorted_indices = above_threshold[np.argsort(protein_predictions[above_threshold])[::-1]]\n",
    "    \n",
    "    # Limit to max terms per protein\n",
    "    sorted_indices = sorted_indices[:max_terms_per_protein]\n",
    "    \n",
    "    # Add to submission\n",
    "    for idx in sorted_indices:\n",
    "        go_term = all_go_terms[idx]\n",
    "        score = protein_predictions[idx]\n",
    "        submission_data.append([protein_id, go_term, f\"{score:.3f}\"])\n",
    "\n",
    "print(f\"Created {len(submission_data)} predictions\")\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "submission_df = pd.DataFrame(submission_data, columns=['protein_id', 'go_term', 'score'])\n",
    "print(f\"üìä Submission statistics:\")\n",
    "print(f\"   Total predictions: {len(submission_df)}\")\n",
    "print(f\"   Unique proteins: {submission_df['protein_id'].nunique()}\")\n",
    "print(f\"   Average predictions per protein: {len(submission_df) / submission_df['protein_id'].nunique():.1f}\")\n",
    "\n",
    "# Show sample predictions\n",
    "print(f\"\\nüîç Sample predictions:\")\n",
    "print(submission_df.head(10))\n",
    "\n",
    "# Save submission file\n",
    "submission_path = os.path.join(base_path, \"my_protein_predictions.tsv\")\n",
    "# Format for competition: protein_id, go_term, score (tab-separated, no header)\n",
    "with open(submission_path, 'w') as f:\n",
    "    for _, row in submission_df.iterrows():\n",
    "        f.write(f\"{row['protein_id']}\\t{row['go_term']}\\t{row['score']}\\n\")\n",
    "\n",
    "print(f\"\\n‚úÖ Submission saved to: {submission_path}\")\n",
    "print(\"üéâ Protein function prediction model completed!\")\n",
    "\n",
    "# Model summary\n",
    "print(f\"\\nüìã Final Model Summary:\")\n",
    "print(f\"   Model type: CNN + LSTM + Attention\")\n",
    "print(f\"   Training proteins: {len(train_sequences_list)}\")\n",
    "print(f\"   GO terms predicted: {len(all_go_terms)}\")\n",
    "print(f\"   Final validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"   Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"   Predictions generated: {len(submission_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eaa24c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Configuring PyTorch for NVIDIA A5000 GPU...\n",
      "‚úÖ GPU: NVIDIA RTX 5000 Ada Generation Laptop GPU\n",
      "üíæ Memory: 17.2 GB\n",
      "‚ö° Compute Capability: 8.9\n",
      "üî• Multi-processors: 76\n",
      "üìä Reserved GPU memory: 15.5 GB\n",
      "üéØ Device set to: cuda:0\n",
      "‚úÖ PyTorch GPU configuration complete!\n"
     ]
    }
   ],
   "source": [
    "# Complete GPU-optimized PyTorch setup for NVIDIA A5000\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Force GPU usage and configure for A5000\n",
    "print(\"üöÄ Configuring PyTorch for NVIDIA A5000 GPU...\")\n",
    "\n",
    "# Ensure CUDA is available\n",
    "assert torch.cuda.is_available(), \"CUDA is not available!\"\n",
    "\n",
    "# Set device and configure for A5000\n",
    "device = torch.device('cuda:0')\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# A5000 optimizations\n",
    "torch.backends.cudnn.benchmark = True  # Optimize for consistent input sizes\n",
    "torch.backends.cudnn.deterministic = False  # Allow non-deterministic for speed\n",
    "torch.cuda.empty_cache()  # Clear GPU memory\n",
    "\n",
    "# Display GPU info\n",
    "gpu_props = torch.cuda.get_device_properties(0)\n",
    "print(f\"‚úÖ GPU: {gpu_props.name}\")\n",
    "print(f\"üíæ Memory: {gpu_props.total_memory / 1e9:.1f} GB\")\n",
    "print(f\"‚ö° Compute Capability: {gpu_props.major}.{gpu_props.minor}\")\n",
    "print(f\"üî• Multi-processors: {gpu_props.multi_processor_count}\")\n",
    "\n",
    "# Set memory management for better performance\n",
    "torch.cuda.set_per_process_memory_fraction(0.9)  # Use 90% of GPU memory\n",
    "print(f\"üìä Reserved GPU memory: {gpu_props.total_memory * 0.9 / 1e9:.1f} GB\")\n",
    "\n",
    "print(f\"üéØ Device set to: {device}\")\n",
    "print(\"‚úÖ PyTorch GPU configuration complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318aa02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading and preparing data for GPU training...\n",
      "üì• Loading fresh data...\n",
      "üìä Loaded 537027 annotations for 82404 proteins\n",
      "   Loaded 1000 sequences...\n",
      "   Loaded 2000 sequences...\n",
      "   Loaded 3000 sequences...\n",
      "   Loaded 4000 sequences...\n",
      "   Loaded 5000 sequences...\n",
      "   Loaded 6000 sequences...\n",
      "   Loaded 7000 sequences...\n",
      "   Loaded 8000 sequences...\n",
      "   Loaded 9000 sequences...\n",
      "üîó Found 10000 proteins with both sequences and annotations\n",
      "üéØ Total GO terms: 26125\n",
      "‚úÖ Data preparation complete!\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data efficiently for GPU training\n",
    "print(\"üìÇ Loading and preparing data for GPU training...\")\n",
    "\n",
    "# Use existing data from previous cells if available\n",
    "try:\n",
    "    # Check if data is already loaded\n",
    "    if 'train_sequences' in globals() and 'train_terms' in globals():\n",
    "        print(\"‚úÖ Using existing training data\")\n",
    "    else:\n",
    "        raise NameError(\"Data not found\")\n",
    "except:\n",
    "    print(\"üì• Loading fresh data...\")\n",
    "    # Define file paths\n",
    "    base_path = r\"c:\\Users\\USANBRO30\\OneDrive - ABB\\Documents\\GitHub\\Monthly-Flash-Report-Pricing\\kaggle_comps\\CAFA 6 Protein Function Prediction\"\n",
    "    train_sequences_path = os.path.join(base_path, \"Train\", \"train_sequences.fasta\")\n",
    "    train_terms_path = os.path.join(base_path, \"Train\", \"train_terms.tsv\")\n",
    "    \n",
    "    # Load training terms\n",
    "    train_terms = pd.read_csv(train_terms_path, sep='\\t')\n",
    "    print(f\"üìä Loaded {len(train_terms)} annotations for {train_terms['EntryID'].nunique()} proteins\")\n",
    "    \n",
    "    # Load sequences efficiently\n",
    "    def load_sequences_fast(fasta_path, max_proteins=10000):\n",
    "        \"\"\"Load protein sequences efficiently\"\"\"\n",
    "        sequences = {}\n",
    "        count = 0\n",
    "        with open(fasta_path, 'r') as handle:\n",
    "            for record in SeqIO.parse(handle, \"fasta\"):\n",
    "                sequences[record.id] = str(record.seq)\n",
    "                count += 1\n",
    "                if count >= max_proteins:\n",
    "                    break\n",
    "                if count % 1000 == 0:\n",
    "                    print(f\"   Loaded {count} sequences...\")\n",
    "        return sequences\n",
    "    \n",
    "    train_sequences = load_sequences_fast(train_sequences_path, max_proteins=10000)\n",
    "\n",
    "# Create protein ID mapping\n",
    "sequence_id_mapping = {}\n",
    "for seq_id in train_sequences.keys():\n",
    "    if '|' in seq_id:\n",
    "        parts = seq_id.split('|')\n",
    "        if len(parts) >= 2:\n",
    "            protein_id = parts[1]\n",
    "            sequence_id_mapping[protein_id] = seq_id\n",
    "\n",
    "# Find available proteins\n",
    "available_protein_ids = set(sequence_id_mapping.keys()) & set(train_terms['EntryID'].unique())\n",
    "print(f\"üîó Found {len(available_protein_ids)} proteins with both sequences and annotations\")\n",
    "\n",
    "# Prepare GO terms\n",
    "all_go_terms = sorted(train_terms['term'].unique())\n",
    "go_term_to_idx = {term: idx for idx, term in enumerate(all_go_terms)}\n",
    "print(f\"üéØ Total GO terms: {len(all_go_terms)}\")\n",
    "\n",
    "print(\"‚úÖ Data preparation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ca554e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Creating GPU-optimized training dataset...\n",
      "Using 5000 proteins for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5000/5000 [01:22<00:00, 60.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset ready: 5000 proteins\n",
      "üìà Average GO terms per protein: 10.80\n",
      "üìã Train: 4000, Validation: 1000\n",
      "üîÑ Pre-processing sequences for GPU training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4000/4000 [00:00<00:00, 19409.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Pre-processing sequences for GPU training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 18624.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# GPU-optimized Dataset class\n",
    "class ProteinGPUDataset(Dataset):\n",
    "    def __init__(self, sequences, labels, max_length=1024):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Amino acid vocabulary (20 standard + special tokens)\n",
    "        self.aa_vocab = {\n",
    "            'A': 1, 'R': 2, 'N': 3, 'D': 4, 'C': 5, 'Q': 6, 'E': 7, 'G': 8,\n",
    "            'H': 9, 'I': 10, 'L': 11, 'K': 12, 'M': 13, 'F': 14, 'P': 15, 'S': 16,\n",
    "            'T': 17, 'W': 18, 'Y': 19, 'V': 20, '<PAD>': 0, '<UNK>': 21\n",
    "        }\n",
    "        \n",
    "        # Pre-process all sequences for faster training\n",
    "        self.processed_sequences = self._preprocess_sequences()\n",
    "        \n",
    "    def _preprocess_sequences(self):\n",
    "        \"\"\"Pre-process all sequences to avoid doing it during training\"\"\"\n",
    "        processed = []\n",
    "        print(\"üîÑ Pre-processing sequences for GPU training...\")\n",
    "        \n",
    "        for sequence in tqdm(self.sequences, desc=\"Processing\"):\n",
    "            # Convert to indices\n",
    "            seq_indices = [self.aa_vocab.get(aa, self.aa_vocab['<UNK>']) for aa in sequence]\n",
    "            \n",
    "            # Truncate or pad\n",
    "            if len(seq_indices) > self.max_length:\n",
    "                seq_indices = seq_indices[:self.max_length]\n",
    "            else:\n",
    "                seq_indices += [self.aa_vocab['<PAD>']] * (self.max_length - len(seq_indices))\n",
    "            \n",
    "            processed.append(torch.tensor(seq_indices, dtype=torch.long))\n",
    "        \n",
    "        return processed\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.processed_sequences[idx], torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "# Create training dataset efficiently\n",
    "print(\"üìä Creating GPU-optimized training dataset...\")\n",
    "\n",
    "# Select subset for faster training (you can increase this later)\n",
    "protein_subset = list(available_protein_ids)[:5000]\n",
    "print(f\"Using {len(protein_subset)} proteins for training\")\n",
    "\n",
    "# Prepare sequences and labels\n",
    "sequences_list = []\n",
    "labels_list = []\n",
    "\n",
    "for protein_id in tqdm(protein_subset, desc=\"Preparing data\"):\n",
    "    # Get sequence\n",
    "    fasta_id = sequence_id_mapping[protein_id]\n",
    "    sequence = train_sequences[fasta_id]\n",
    "    \n",
    "    # Get GO terms\n",
    "    protein_go_terms = train_terms[train_terms['EntryID'] == protein_id]['term'].values\n",
    "    \n",
    "    # Create label vector\n",
    "    label_vector = np.zeros(len(all_go_terms), dtype=np.float32)\n",
    "    for go_term in protein_go_terms:\n",
    "        if go_term in go_term_to_idx:\n",
    "            label_vector[go_term_to_idx[go_term]] = 1.0\n",
    "    \n",
    "    # Only include if has labels\n",
    "    if label_vector.sum() > 0:\n",
    "        sequences_list.append(sequence)\n",
    "        labels_list.append(label_vector)\n",
    "\n",
    "print(f\"‚úÖ Dataset ready: {len(sequences_list)} proteins\")\n",
    "print(f\"üìà Average GO terms per protein: {np.mean([labels.sum() for labels in labels_list]):.2f}\")\n",
    "\n",
    "# Split into train/validation\n",
    "train_seqs, val_seqs, train_labels, val_labels = train_test_split(\n",
    "    sequences_list, labels_list, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üìã Train: {len(train_seqs)}, Validation: {len(val_seqs)}\")\n",
    "\n",
    "# Create datasets with shorter sequences for faster GPU training\n",
    "train_dataset = ProteinGPUDataset(train_seqs, train_labels, max_length=512)\n",
    "val_dataset = ProteinGPUDataset(val_seqs, val_labels, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca5480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è  Creating GPU-optimized model...\n",
      "üìä GPU Model Statistics:\n",
      "   Total parameters: 15,520,781\n",
      "   Trainable parameters: 15,520,781\n",
      "   Model size: ~62.1 MB\n",
      "   Device: cuda:0\n",
      "\n",
      "üß™ Testing GPU forward pass...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USANBRO30\\AppData\\Local\\anaconda3\\envs\\DataScience\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPU forward pass successful!\n",
      "   Input shape: torch.Size([4, 512])\n",
      "   Output shape: torch.Size([4, 26125])\n",
      "   Inference time: 0.5206 seconds\n",
      "   Output range: [0.3278, 0.6561]\n",
      "üöÄ GPU model ready for training!\n"
     ]
    }
   ],
   "source": [
    "# GPU-optimized Protein Function Prediction Model\n",
    "class GPUProteinPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size=22, embedding_dim=256, hidden_dim=512, \n",
    "                 num_classes=26125, max_length=512, dropout=0.1):\n",
    "        super(GPUProteinPredictor, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Embedding layer with larger dimension for better representation\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        # Multi-scale convolutional layers for pattern detection\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv1d(embedding_dim, hidden_dim, kernel_size=k, padding=k//2)\n",
    "            for k in [3, 5, 7, 9]  # Multiple kernel sizes\n",
    "        ])\n",
    "        \n",
    "        # Batch normalization for each conv layer\n",
    "        self.batch_norms = nn.ModuleList([\n",
    "            nn.BatchNorm1d(hidden_dim) for _ in range(4)\n",
    "        ])\n",
    "        \n",
    "        # Combine convolution outputs\n",
    "        self.conv_combine = nn.Conv1d(hidden_dim * 4, hidden_dim, kernel_size=1)\n",
    "        \n",
    "        # Bidirectional LSTM layers\n",
    "        self.lstm1 = nn.LSTM(hidden_dim, hidden_dim//2, batch_first=True, \n",
    "                            bidirectional=True, dropout=dropout)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim//2, batch_first=True, \n",
    "                            bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        # Multi-head attention for important region focus\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim, \n",
    "            num_heads=8, \n",
    "            dropout=dropout, \n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Classification head with multiple layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_dim//2),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim//2, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize model weights for better convergence\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                nn.init.xavier_normal_(module.weight)\n",
    "            elif isinstance(module, (nn.BatchNorm1d, nn.LayerNorm)):\n",
    "                nn.init.ones_(module.weight)\n",
    "                nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        \n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_len, embedding_dim)\n",
    "        embedded = embedded.transpose(1, 2)  # (batch_size, embedding_dim, seq_len)\n",
    "        \n",
    "        # Multi-scale convolutions\n",
    "        conv_outputs = []\n",
    "        for conv_layer, batch_norm in zip(self.conv_layers, self.batch_norms):\n",
    "            conv_out = self.relu(batch_norm(conv_layer(embedded)))\n",
    "            conv_outputs.append(conv_out)\n",
    "        \n",
    "        # Combine convolution outputs\n",
    "        conv_combined = torch.cat(conv_outputs, dim=1)  # (batch_size, hidden_dim*4, seq_len)\n",
    "        conv_combined = self.relu(self.conv_combine(conv_combined))  # (batch_size, hidden_dim, seq_len)\n",
    "        conv_combined = conv_combined.transpose(1, 2)  # (batch_size, seq_len, hidden_dim)\n",
    "        \n",
    "        # LSTM layers\n",
    "        lstm_out1, _ = self.lstm1(conv_combined)\n",
    "        lstm_out1 = self.dropout(lstm_out1)\n",
    "        lstm_out2, _ = self.lstm2(lstm_out1)\n",
    "        \n",
    "        # Self-attention\n",
    "        attended_out, _ = self.attention(lstm_out2, lstm_out2, lstm_out2)\n",
    "        \n",
    "        # Global pooling (max and mean)\n",
    "        max_pool = torch.max(attended_out, dim=1)[0]\n",
    "        mean_pool = torch.mean(attended_out, dim=1)\n",
    "        \n",
    "        # Combine pooled features\n",
    "        combined = max_pool + mean_pool  # (batch_size, hidden_dim)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(combined)\n",
    "        return torch.sigmoid(output)  # Multi-label classification\n",
    "\n",
    "# Initialize the GPU model\n",
    "print(\"üèóÔ∏è  Creating GPU-optimized model...\")\n",
    "model = GPUProteinPredictor(\n",
    "    vocab_size=22,\n",
    "    embedding_dim=256,  # Larger embedding for GPU\n",
    "    hidden_dim=512,     # Larger hidden dimension\n",
    "    num_classes=len(all_go_terms),\n",
    "    max_length=512,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"üìä GPU Model Statistics:\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"   Model size: ~{total_params * 4 / 1e6:.1f} MB\")\n",
    "print(f\"   Device: {next(model.parameters()).device}\")\n",
    "\n",
    "# Test forward pass on GPU\n",
    "print(\"\\nüß™ Testing GPU forward pass...\")\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randint(0, 22, (4, 512)).to(device)\n",
    "    start_time = time.time()\n",
    "    test_output = model(test_input)\n",
    "    gpu_inference_time = time.time() - start_time\n",
    "    \n",
    "print(f\"‚úÖ GPU forward pass successful!\")\n",
    "print(f\"   Input shape: {test_input.shape}\")\n",
    "print(f\"   Output shape: {test_output.shape}\")\n",
    "print(f\"   Inference time: {gpu_inference_time:.4f} seconds\")\n",
    "print(f\"   Output range: [{test_output.min():.4f}, {test_output.max():.4f}]\")\n",
    "\n",
    "torch.cuda.empty_cache()  # Clear GPU memory\n",
    "print(\"üöÄ GPU model ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28f5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è  Setting up GPU training components...\n",
      "üìä DataLoaders created:\n",
      "   Batch size: 32\n",
      "   Training batches: 125\n",
      "   Validation batches: 32\n",
      "   Workers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USANBRO30\\AppData\\Local\\Temp\\ipykernel_6824\\3449618329.py:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training components configured:\n",
      "   Optimizer: AdamW\n",
      "   Scheduler: OneCycleLR\n",
      "   Mixed precision: Enabled\n",
      "   Loss function: BCELoss\n",
      "üöÄ GPU training functions ready!\n",
      "\n",
      "‚è±Ô∏è  Testing data loading speed...\n"
     ]
    }
   ],
   "source": [
    "# GPU-optimized training setup\n",
    "print(\"‚öôÔ∏è  Setting up GPU training components...\")\n",
    "\n",
    "# Create data loaders optimized for GPU\n",
    "batch_size = 32  # Larger batch size for GPU efficiency\n",
    "num_workers = 4  # Parallel data loading\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,  # Faster GPU transfer\n",
    "    persistent_workers=True  # Keep workers alive\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "print(f\"üìä DataLoaders created:\")\n",
    "print(f\"   Batch size: {batch_size}\")\n",
    "print(f\"   Training batches: {len(train_loader)}\")\n",
    "print(f\"   Validation batches: {len(val_loader)}\")\n",
    "print(f\"   Workers: {num_workers}\")\n",
    "\n",
    "# Loss function and optimizer optimized for GPU\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# AdamW optimizer with weight decay\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=0.001, \n",
    "    weight_decay=0.01,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=0.003,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy='cos'\n",
    ")\n",
    "\n",
    "# Mixed precision training for better GPU utilization\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "print(\"‚úÖ Training components configured:\")\n",
    "print(f\"   Optimizer: AdamW\")\n",
    "print(f\"   Scheduler: OneCycleLR\")\n",
    "print(f\"   Mixed precision: Enabled\")\n",
    "print(f\"   Loss function: BCELoss\")\n",
    "\n",
    "# GPU-optimized training functions\n",
    "def train_epoch_gpu(model, loader, optimizer, criterion, scaler, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc=\"Training\")\n",
    "    for batch_idx, (sequences, labels) in enumerate(pbar):\n",
    "        # Move data to GPU efficiently\n",
    "        sequences = sequences.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed precision forward pass\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Mixed precision backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Avg Loss': f'{total_loss/num_batches:.4f}',\n",
    "            'LR': f'{scheduler.get_last_lr()[0]:.6f}'\n",
    "        })\n",
    "        \n",
    "        # Memory management\n",
    "        if batch_idx % 50 == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "def validate_epoch_gpu(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Validation\")\n",
    "        for sequences, labels in pbar:\n",
    "            sequences = sequences.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(sequences)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            # Store for metrics calculation\n",
    "            all_outputs.append(outputs.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "            \n",
    "            pbar.set_postfix({'Val Loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    # Calculate metrics\n",
    "    all_outputs = torch.cat(all_outputs, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    \n",
    "    # Calculate precision, recall, F1\n",
    "    threshold = 0.5\n",
    "    predicted = (all_outputs > threshold).float()\n",
    "    \n",
    "    tp = (all_labels * predicted).sum()\n",
    "    fp = ((1 - all_labels) * predicted).sum()\n",
    "    fn = (all_labels * (1 - predicted)).sum()\n",
    "    \n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    \n",
    "    return total_loss / num_batches, precision.item(), recall.item(), f1.item()\n",
    "\n",
    "print(\"üöÄ GPU training functions ready!\")\n",
    "\n",
    "# Test data loading speed\n",
    "print(\"\\n‚è±Ô∏è  Testing data loading speed...\")\n",
    "start_time = time.time()\n",
    "sample_batch = next(iter(train_loader))\n",
    "load_time = time.time() - start_time\n",
    "print(f\"   Batch loading time: {load_time:.4f} seconds\")\n",
    "print(f\"   Sequences shape: {sample_batch[0].shape}\")\n",
    "print(f\"   Labels shape: {sample_batch[1].shape}\")\n",
    "print(f\"   Memory usage: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "print(\"\\n‚úÖ Ready to start GPU training!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
